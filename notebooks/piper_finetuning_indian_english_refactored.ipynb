{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "159c9321",
   "metadata": {},
   "source": [
    "# Piper TTS Fine-Tuning: Indian English Voice\n",
    "\n",
    "This notebook provides a complete pipeline for fine-tuning the Piper TTS model.\n",
    "\n",
    "**Supports two modes:**\n",
    "- **COLAB mode (`COLAB = True`)**: Uses Google Drive for data storage (Proof of Concept)\n",
    "- **Production mode (`COLAB = False`)**: Uses AWS S3 for data storage (Production-ready)\n",
    "\n",
    "**Compatible with:** Google Colab, AWS SageMaker\n",
    "\n",
    "## Table of Contents\n",
    "1. [Environment Configuration](#1-environment-configuration)\n",
    "2. [Configuration Dataclass](#2-configuration-dataclass)\n",
    "3. [Environment Setup](#3-environment-setup)\n",
    "4. [Install Software Dependencies](#4-install-software-dependencies)\n",
    "5. [Data ETL](#5-data-etl)\n",
    "6. [Training](#6-training)\n",
    "7. [Save Training Outputs](#7-save-training-outputs)\n",
    "8. [Test Model from Checkpoint](#8-test-model-from-checkpoint)\n",
    "9. [Export to ONNX](#9-export-to-onnx)\n",
    "10. [Test ONNX Model](#10-test-onnx-model)\n",
    "\n",
    "---\n",
    "\n",
    "**Repository:** https://github.com/Vinit-source/piper1-gpl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdba337",
   "metadata": {},
   "source": [
    "# ðŸ”§ **1. Environment Configuration**\n",
    "\n",
    "Set the `COLAB` constant to select between:\n",
    "- `COLAB = True`: Google Drive mode (Proof of Concept)\n",
    "- `COLAB = False`: AWS S3 mode (Production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20802ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ENVIRONMENT MODE SELECTION\n",
    "# =============================================================================\n",
    "# Set COLAB = True for Google Drive mode (Proof of Concept)\n",
    "# Set COLAB = False for AWS S3 mode (Production)\n",
    "\n",
    "COLAB: bool = True  # Toggle between Colab (Google Drive) and AWS (S3) mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a9d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION DATACLASS\n",
    "# =============================================================================\n",
    "# Centralized configuration for all pipeline parameters.\n",
    "# All required fields must be set - no fallback values are used.\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PiperConfig:\n",
    "    \"\"\"\n",
    "    Configuration for Piper TTS fine-tuning pipeline.\n",
    "    \n",
    "    Attributes:\n",
    "        colab_mode: Whether running in Colab (Google Drive) or AWS (S3) mode\n",
    "        \n",
    "    Google Drive Configuration (COLAB = True):\n",
    "        gdrive_dataset_path: Path to dataset folder in Google Drive\n",
    "        gdrive_output_path: Path to save outputs in Google Drive\n",
    "        \n",
    "    AWS S3 Configuration (COLAB = False):\n",
    "        s3_bucket: S3 bucket name\n",
    "        s3_dataset_prefix: S3 prefix for dataset\n",
    "        s3_checkpoint_prefix: S3 prefix for checkpoints\n",
    "        aws_region: AWS region\n",
    "        aws_access_key_id: AWS access key (optional, uses IAM role if not set)\n",
    "        aws_secret_access_key: AWS secret key (optional, uses IAM role if not set)\n",
    "        \n",
    "    Model Configuration:\n",
    "        model_name: Name for the output model\n",
    "        espeak_voice: eSpeak voice for phonemization\n",
    "        sample_rate: Audio sample rate in Hz\n",
    "        \n",
    "    Training Configuration:\n",
    "        batch_size: Training batch size\n",
    "        max_epochs: Maximum training epochs\n",
    "        validation_split: Fraction of data for validation\n",
    "        num_test_examples: Number of test examples for audio generation\n",
    "        learning_rate: Learning rate for fine-tuning\n",
    "        precision: Training precision (e.g., \"16-mixed\", \"32\")\n",
    "        checkpoint_epochs: Save checkpoint every N epochs\n",
    "        device: Training device (\"cpu\" or \"gpu\")\n",
    "        use_pretrained: Whether to use pretrained checkpoint\n",
    "        resume_training: Whether to resume from existing checkpoint\n",
    "    \"\"\"\n",
    "    \n",
    "    # Environment mode\n",
    "    colab_mode: bool = True\n",
    "    \n",
    "    # ==================== GOOGLE DRIVE CONFIGURATION ====================\n",
    "    # Required when COLAB = True\n",
    "    gdrive_dataset_path: str = \"<GDRIVE_DATASET_PATH>\"  # e.g., \"/content/drive/MyDrive/Piper-POC-Training/\"\n",
    "    gdrive_output_path: str = \"<GDRIVE_OUTPUT_PATH>\"    # e.g., \"/content/drive/MyDrive/Piper-POC-Training/output\"\n",
    "    \n",
    "    # ==================== AWS S3 CONFIGURATION ====================\n",
    "    # Required when COLAB = False\n",
    "    s3_bucket: str = \"<YOUR_S3_BUCKET_NAME>\"           # e.g., \"my-tts-training-bucket\"\n",
    "    s3_dataset_prefix: str = \"<S3_DATASET_PATH>\"       # e.g., \"datasets/spicor\"\n",
    "    s3_checkpoint_prefix: str = \"<S3_CHECKPOINT_PATH>\" # e.g., \"checkpoints/piper\"\n",
    "    aws_region: str = \"<AWS_REGION>\"                   # e.g., \"us-east-1\"\n",
    "    aws_access_key_id: Optional[str] = None            # Leave None to use IAM role\n",
    "    aws_secret_access_key: Optional[str] = None        # Leave None to use IAM role\n",
    "    \n",
    "    # ==================== MODEL CONFIGURATION ====================\n",
    "    model_name: str = \"<MODEL_NAME>\"                   # e.g., \"en_IN-spicor-medium\"\n",
    "    espeak_voice: str = \"en-us\"                        # eSpeak voice for phonemization\n",
    "    sample_rate: int = 22050                           # Audio sample rate\n",
    "    num_speakers: int = 1                              # Number of speakers (1 for single speaker)\n",
    "    \n",
    "    # ==================== TRAINING CONFIGURATION ====================\n",
    "    batch_size: int = 8                                # Reduce if out of memory\n",
    "    max_epochs: int = 4000                             # Maximum training epochs\n",
    "    validation_split: float = 0.0                      # Validation split (0.0 to disable)\n",
    "    num_test_examples: int = 0                         # Test examples for audio generation\n",
    "    learning_rate: float = 1e-4                        # Learning rate\n",
    "    precision: str = \"32\"                              # Training precision (\"16-mixed\" or \"32\")\n",
    "    checkpoint_epochs: int = 200                       # Save checkpoint every N epochs\n",
    "    device: str = \"gpu\"                                # \"cpu\" or \"gpu\"\n",
    "    use_pretrained: bool = True                        # Use pretrained checkpoint\n",
    "    resume_training: bool = False                      # Resume from existing checkpoint\n",
    "    \n",
    "    # ==================== LOCAL PATHS (Auto-configured) ====================\n",
    "    base_dir: str = field(default=\"\")\n",
    "    local_dataset_dir: str = field(default=\"\")\n",
    "    local_wavs_dir: str = field(default=\"\")\n",
    "    local_cache_dir: str = field(default=\"\")\n",
    "    local_output_dir: str = field(default=\"\")\n",
    "    piper_dir: str = field(default=\"\")\n",
    "    \n",
    "    # ==================== HUGGING FACE CHECKPOINT ====================\n",
    "    hf_checkpoint_repo: str = \"rhasspy/piper-checkpoints\"\n",
    "    hf_checkpoint_path: str = \"en/en_US/ljspeech/high/ljspeech-2000.ckpt\"\n",
    "    hf_config_path: str = \"en/en_US/ljspeech/high/config.json\"\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Initialize derived paths based on environment mode.\"\"\"\n",
    "        if self.colab_mode:\n",
    "            self.base_dir = \"/content\"\n",
    "            self.piper_dir = \"/content/piper1-gpl\"\n",
    "        else:\n",
    "            self.base_dir = \"./piper_training\"\n",
    "            self.piper_dir = \"./piper1-gpl\"\n",
    "        \n",
    "        self.local_dataset_dir = f\"{self.base_dir}/dataset\"\n",
    "        self.local_wavs_dir = f\"{self.local_dataset_dir}/wavs\"\n",
    "        self.local_cache_dir = f\"{self.base_dir}/audio_cache\"\n",
    "        self.local_output_dir = f\"{self.base_dir}/output/{self.model_name}\"\n",
    "    \n",
    "    def validate(self) -> None:\n",
    "        \"\"\"\n",
    "        Validate configuration and raise errors for missing required fields.\n",
    "        No fallback values - all placeholders must be replaced.\n",
    "        \"\"\"\n",
    "        errors = []\n",
    "        \n",
    "        # Validate model name\n",
    "        if self.model_name == \"<MODEL_NAME>\" or not self.model_name:\n",
    "            errors.append(\"model_name: Must be set (e.g., 'en_IN-spicor-medium')\")\n",
    "        \n",
    "        if self.colab_mode:\n",
    "            # Validate Google Drive configuration\n",
    "            if self.gdrive_dataset_path == \"<GDRIVE_DATASET_PATH>\" or not self.gdrive_dataset_path:\n",
    "                errors.append(\"gdrive_dataset_path: Must be set for COLAB mode\")\n",
    "            if self.gdrive_output_path == \"<GDRIVE_OUTPUT_PATH>\" or not self.gdrive_output_path:\n",
    "                errors.append(\"gdrive_output_path: Must be set for COLAB mode\")\n",
    "        else:\n",
    "            # Validate AWS S3 configuration\n",
    "            if self.s3_bucket == \"<YOUR_S3_BUCKET_NAME>\" or not self.s3_bucket:\n",
    "                errors.append(\"s3_bucket: Must be set for AWS mode\")\n",
    "            if self.s3_dataset_prefix == \"<S3_DATASET_PATH>\" or not self.s3_dataset_prefix:\n",
    "                errors.append(\"s3_dataset_prefix: Must be set for AWS mode\")\n",
    "            if self.s3_checkpoint_prefix == \"<S3_CHECKPOINT_PATH>\" or not self.s3_checkpoint_prefix:\n",
    "                errors.append(\"s3_checkpoint_prefix: Must be set for AWS mode\")\n",
    "            if self.aws_region == \"<AWS_REGION>\" or not self.aws_region:\n",
    "                errors.append(\"aws_region: Must be set for AWS mode\")\n",
    "        \n",
    "        # Validate training parameters\n",
    "        if self.batch_size <= 0:\n",
    "            errors.append(\"batch_size: Must be positive\")\n",
    "        if self.max_epochs <= 0:\n",
    "            errors.append(\"max_epochs: Must be positive\")\n",
    "        if self.sample_rate <= 0:\n",
    "            errors.append(\"sample_rate: Must be positive\")\n",
    "        if self.device not in (\"cpu\", \"gpu\"):\n",
    "            errors.append(\"device: Must be 'cpu' or 'gpu'\")\n",
    "        \n",
    "        if errors:\n",
    "            error_msg = \"Configuration validation failed:\\n\" + \"\\n\".join(f\"  - {e}\" for e in errors)\n",
    "            raise ValueError(error_msg)\n",
    "    \n",
    "    def create_directories(self) -> None:\n",
    "        \"\"\"Create all required local directories.\"\"\"\n",
    "        dirs = [\n",
    "            self.local_dataset_dir,\n",
    "            self.local_wavs_dir,\n",
    "            self.local_cache_dir,\n",
    "            self.local_output_dir,\n",
    "        ]\n",
    "        for d in dirs:\n",
    "            Path(d).mkdir(parents=True, exist_ok=True)\n",
    "            print(f\"Created directory: {d}\")\n",
    "        \n",
    "        # Create Google Drive output directory if in COLAB mode\n",
    "        if self.colab_mode:\n",
    "            Path(self.gdrive_output_path).mkdir(parents=True, exist_ok=True)\n",
    "            print(f\"Created Google Drive output directory: {self.gdrive_output_path}\")\n",
    "\n",
    "\n",
    "def detect_runtime_environment() -> str:\n",
    "    \"\"\"\n",
    "    Detect the current runtime environment.\n",
    "    \n",
    "    Returns:\n",
    "        str: 'colab', 'sagemaker', or 'local'\n",
    "    \"\"\"\n",
    "    if 'google.colab' in sys.modules:\n",
    "        return 'colab'\n",
    "    elif os.environ.get('SM_CURRENT_HOST'):\n",
    "        return 'sagemaker'\n",
    "    return 'local'\n",
    "\n",
    "\n",
    "# Display detected environment\n",
    "RUNTIME_ENV = detect_runtime_environment()\n",
    "print(f\"Detected runtime environment: {RUNTIME_ENV}\")\n",
    "print(f\"Mode: {'Google Colab (Google Drive)' if COLAB else 'Production (AWS S3)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INITIALIZE CONFIGURATION\n",
    "# =============================================================================\n",
    "# Update the configuration values below before running the pipeline.\n",
    "# All placeholder values (e.g., \"<MODEL_NAME>\") must be replaced.\n",
    "\n",
    "config = PiperConfig(\n",
    "    colab_mode=COLAB,\n",
    "    \n",
    "    # ----- Google Drive Configuration (for COLAB = True) -----\n",
    "    gdrive_dataset_path=\"/content/drive/MyDrive/Piper-POC-Training/\",\n",
    "    gdrive_output_path=\"/content/drive/MyDrive/Piper-POC-Training/output\",\n",
    "    \n",
    "    # ----- AWS S3 Configuration (for COLAB = False) -----\n",
    "    s3_bucket=\"<YOUR_S3_BUCKET_NAME>\",\n",
    "    s3_dataset_prefix=\"<S3_DATASET_PATH>\",\n",
    "    s3_checkpoint_prefix=\"<S3_CHECKPOINT_PATH>\",\n",
    "    aws_region=\"<AWS_REGION>\",\n",
    "    aws_access_key_id=None,  # Set to None to use IAM role\n",
    "    aws_secret_access_key=None,\n",
    "    \n",
    "    # ----- Model Configuration -----\n",
    "    model_name=\"en_IN-spicor-medium\",\n",
    "    espeak_voice=\"en-us\",\n",
    "    sample_rate=22050,\n",
    "    num_speakers=1,  # 1 for single speaker\n",
    "    \n",
    "    # ----- Training Configuration -----\n",
    "    batch_size=8,\n",
    "    max_epochs=4000,\n",
    "    validation_split=0.0,\n",
    "    num_test_examples=0,\n",
    "    learning_rate=1e-4,\n",
    "    precision=\"32\",\n",
    "    checkpoint_epochs=200,\n",
    "    device=\"gpu\",\n",
    "    use_pretrained=True,\n",
    "    resume_training=False,\n",
    ")\n",
    "\n",
    "# Validate configuration - raises error if any required field is missing\n",
    "config.validate()\n",
    "\n",
    "# Create local directories\n",
    "config.create_directories()\n",
    "\n",
    "# Display configuration summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONFIGURATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Mode: {'COLAB (Google Drive)' if config.colab_mode else 'AWS (S3)'}\")\n",
    "print(f\"Model name: {config.model_name}\")\n",
    "print(f\"Sample rate: {config.sample_rate}\")\n",
    "print(f\"Batch size: {config.batch_size}\")\n",
    "print(f\"Max epochs: {config.max_epochs}\")\n",
    "print(f\"Device: {config.device}\")\n",
    "print(f\"Use pretrained: {config.use_pretrained}\")\n",
    "print(f\"Local output: {config.local_output_dir}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3293f1e7",
   "metadata": {},
   "source": [
    "# ðŸ–¥ï¸ **2. Environment Setup**\n",
    "\n",
    "Set up the runtime environment including GPU check and Google Drive mount (if in COLAB mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04073bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GPU CHECK\n",
    "# =============================================================================\n",
    "# Check available GPU. A higher capable GPU leads to faster training speeds.\n",
    "# Default Colab GPU is Tesla T4.\n",
    "\n",
    "print(\"Checking GPU availability...\")\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"\\nâœ… GPU available: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ No GPU detected. Training will be slow on CPU.\")\n",
    "    if config.device == \"gpu\":\n",
    "        raise RuntimeError(\"Configuration specifies 'gpu' but no GPU is available. Set config.device='cpu' or use a GPU-enabled runtime.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c15c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MOUNT GOOGLE DRIVE (COLAB MODE ONLY)\n",
    "# =============================================================================\n",
    "# Mount Google Drive to access dataset and save outputs.\n",
    "# This cell only runs in COLAB mode.\n",
    "\n",
    "if COLAB:\n",
    "    print(\"Mounting Google Drive...\")\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    print(\"âœ… Google Drive mounted successfully.\")\n",
    "    \n",
    "    # Verify dataset path exists\n",
    "    if not os.path.exists(config.gdrive_dataset_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Dataset path not found in Google Drive: {config.gdrive_dataset_path}\\n\"\n",
    "            \"Please verify the path exists and contains your dataset.\"\n",
    "        )\n",
    "    print(f\"âœ… Dataset path verified: {config.gdrive_dataset_path}\")\n",
    "else:\n",
    "    print(\"Skipping Google Drive mount (AWS mode).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac28713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COLAB ANTI-DISCONNECT (COLAB MODE ONLY)\n",
    "# =============================================================================\n",
    "# Prevents automatic disconnection in Google Colab.\n",
    "# Note: Colab will still disconnect after 6-12 hours regardless.\n",
    "\n",
    "if COLAB:\n",
    "    import IPython\n",
    "    js_code = '''\n",
    "    function ClickConnect(){\n",
    "        console.log(\"Anti-disconnect: clicking connect button\");\n",
    "        document.querySelector(\"colab-toolbar-button#connect\").click()\n",
    "    }\n",
    "    setInterval(ClickConnect, 60000)\n",
    "    '''\n",
    "    display(IPython.display.Javascript(js_code))\n",
    "    print(\"âœ… Anti-disconnect script activated.\")\n",
    "else:\n",
    "    print(\"Skipping anti-disconnect (not running in Colab).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea10297a",
   "metadata": {},
   "source": [
    "# ðŸ“¦ **3. Install Software Dependencies**\n",
    "\n",
    "Install Piper TTS and all required dependencies for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebdc94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INSTALL SYSTEM DEPENDENCIES\n",
    "# =============================================================================\n",
    "# Install required system packages for audio processing and building native extensions.\n",
    "\n",
    "print(\"Installing system dependencies...\")\n",
    "!apt-get update -qq\n",
    "!apt-get install -y -qq espeak-ng build-essential cmake ninja-build libespeak-ng1 libespeak-ng-dev\n",
    "print(\"âœ… System dependencies installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625112dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CLONE AND INSTALL PIPER TTS\n",
    "# =============================================================================\n",
    "# Clone the piper1-gpl repository and install with training dependencies.\n",
    "\n",
    "import os\n",
    "\n",
    "PIPER_REPO_URL = \"https://github.com/Vinit-source/piper1-gpl.git\"\n",
    "PIPER_BRANCH = \"main\"\n",
    "PIPER_COMMIT = \"fee9b9cefae4ebf9e196cfe994dea418f051506c\"  # Stable release commit\n",
    "\n",
    "# Clone repository if not exists\n",
    "if not os.path.exists(config.piper_dir):\n",
    "    print(f\"Cloning Piper repository from {PIPER_REPO_URL}...\")\n",
    "    !git clone -b {PIPER_BRANCH} {PIPER_REPO_URL} {config.piper_dir}\n",
    "else:\n",
    "    print(f\"Repository already exists at {config.piper_dir}\")\n",
    "\n",
    "# Change to piper directory\n",
    "%cd {config.piper_dir}\n",
    "\n",
    "# Checkout specific commit for reproducibility\n",
    "print(f\"Checking out commit {PIPER_COMMIT}...\")\n",
    "!git checkout -b release0.3.1 {PIPER_COMMIT} 2>/dev/null || git checkout release0.3.1\n",
    "\n",
    "# Uninstall previous installation to ensure clean rebuild\n",
    "print(\"Removing any previous Piper TTS installation...\")\n",
    "!pip uninstall -y piper-tts 2>/dev/null || true\n",
    "\n",
    "# Install Piper with training dependencies\n",
    "print(\"Installing Piper TTS with training dependencies...\")\n",
    "!pip install -e .[train]\n",
    "\n",
    "# Build monotonic alignment module (required for VITS training)\n",
    "print(\"Building monotonic alignment module...\")\n",
    "!bash build_monotonic_align.sh\n",
    "\n",
    "print(\"\\nâœ… Piper TTS installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1e165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BUILD NATIVE EXTENSIONS\n",
    "# =============================================================================\n",
    "# Build the eSpeak bridge and other native extensions.\n",
    "\n",
    "%cd {config.piper_dir}\n",
    "\n",
    "print(\"Installing scikit-build...\")\n",
    "!pip install scikit-build\n",
    "\n",
    "print(\"Building native extensions...\")\n",
    "!python3 setup.py build_ext --inplace\n",
    "\n",
    "print(\"Installing additional dependencies...\")\n",
    "!pip install onnxscript\n",
    "\n",
    "print(\"\\nâœ… Native extensions built successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840eb4ed",
   "metadata": {},
   "source": [
    "# ðŸ“¥ **4. Data ETL (Extract, Transform, Load)**\n",
    "\n",
    "Download and process the dataset. Supports both Google Drive (COLAB mode) and AWS S3 (Production mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700b9622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADER CLASSES\n",
    "# =============================================================================\n",
    "# Abstract data loading with support for both Google Drive and S3.\n",
    "\n",
    "import os\n",
    "import wave\n",
    "import zipfile\n",
    "import datetime\n",
    "import shutil\n",
    "import logging\n",
    "from abc import ABC, abstractmethod\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Optional\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class DataLoaderBase(ABC):\n",
    "    \"\"\"Abstract base class for data loading operations.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: PiperConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    @abstractmethod\n",
    "    def download_dataset(self) -> int:\n",
    "        \"\"\"Download dataset to local directory. Returns number of files downloaded.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def upload_checkpoint(self, local_path: str, remote_key: str) -> bool:\n",
    "        \"\"\"Upload checkpoint to remote storage. Returns success status.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class GoogleDriveDataLoader(DataLoaderBase):\n",
    "    \"\"\"Data loader for Google Drive (COLAB mode).\"\"\"\n",
    "    \n",
    "    def __init__(self, config: PiperConfig):\n",
    "        super().__init__(config)\n",
    "        if not config.colab_mode:\n",
    "            raise ValueError(\"GoogleDriveDataLoader requires COLAB mode (config.colab_mode=True)\")\n",
    "    \n",
    "    def download_dataset(self) -> int:\n",
    "        \"\"\"\n",
    "        Copy dataset from Google Drive to local directory.\n",
    "        \n",
    "        Expected folder structure in Google Drive:\n",
    "            your_dataset_folder/\n",
    "            â”œâ”€â”€ wavs/           # Audio files (WAV format, 22050Hz recommended)\n",
    "            â”‚   â”œâ”€â”€ 1.wav\n",
    "            â”‚   â”œâ”€â”€ 2.wav\n",
    "            â”‚   â””â”€â”€ ...\n",
    "            â””â”€â”€ metadata.csv    # Transcript file (format: wavs/filename.wav|text)\n",
    "        \n",
    "        Returns:\n",
    "            int: Number of audio files copied\n",
    "        \"\"\"\n",
    "        gdrive_path = self.config.gdrive_dataset_path.strip()\n",
    "        \n",
    "        # Validate source path exists\n",
    "        if not os.path.exists(gdrive_path):\n",
    "            raise FileNotFoundError(f\"Dataset folder not found in Google Drive: {gdrive_path}\")\n",
    "        \n",
    "        # Check for wavs folder or zip file\n",
    "        gdrive_wavs_path = os.path.join(gdrive_path, \"wavs\")\n",
    "        gdrive_wavs_zip = os.path.join(gdrive_path, \"wavs.zip\")\n",
    "        \n",
    "        if os.path.exists(gdrive_wavs_zip):\n",
    "            logger.info(\"Found wavs.zip, extracting...\")\n",
    "            with zipfile.ZipFile(gdrive_wavs_zip, 'r') as zip_ref:\n",
    "                zip_ref.extractall(self.config.local_dataset_dir)\n",
    "            \n",
    "            # Handle nested wavs folder if present\n",
    "            nested_wavs = f\"{self.config.local_dataset_dir}/wavs/wavs\"\n",
    "            if os.path.exists(nested_wavs):\n",
    "                for f in os.listdir(nested_wavs):\n",
    "                    shutil.move(f\"{nested_wavs}/{f}\", f\"{self.config.local_wavs_dir}/{f}\")\n",
    "                    \n",
    "        elif os.path.exists(gdrive_wavs_path):\n",
    "            logger.info(\"Found wavs folder, copying...\")\n",
    "            # Use shell copy for better performance with large datasets\n",
    "            os.system(f'cp -r \"{gdrive_wavs_path}\"/* \"{self.config.local_wavs_dir}/\"')\n",
    "        else:\n",
    "            raise FileNotFoundError(\n",
    "                f\"No 'wavs' folder or 'wavs.zip' found in {gdrive_path}\\n\"\n",
    "                \"Expected structure:\\n\"\n",
    "                \"  your_dataset_folder/\\n\"\n",
    "                \"  â”œâ”€â”€ wavs/\\n\"\n",
    "                \"  â”‚   â”œâ”€â”€ 1.wav\\n\"\n",
    "                \"  â”‚   â””â”€â”€ ...\\n\"\n",
    "                \"  â””â”€â”€ metadata.csv\"\n",
    "            )\n",
    "        \n",
    "        # Clean up macOS ghost files\n",
    "        self._cleanup_ghost_files(self.config.local_wavs_dir)\n",
    "        \n",
    "        # Count files\n",
    "        audio_count = len([f for f in os.listdir(self.config.local_wavs_dir) if f.endswith('.wav')])\n",
    "        logger.info(f\"Copied {audio_count} audio files from Google Drive\")\n",
    "        \n",
    "        return audio_count\n",
    "    \n",
    "    def upload_checkpoint(self, local_path: str, remote_key: str) -> bool:\n",
    "        \"\"\"\n",
    "        Copy checkpoint to Google Drive.\n",
    "        \n",
    "        Args:\n",
    "            local_path: Path to local checkpoint file\n",
    "            remote_key: Relative path within gdrive_output_path\n",
    "            \n",
    "        Returns:\n",
    "            bool: Success status\n",
    "        \"\"\"\n",
    "        try:\n",
    "            dest_path = os.path.join(self.config.gdrive_output_path, remote_key)\n",
    "            Path(dest_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy(local_path, dest_path)\n",
    "            logger.info(f\"Uploaded checkpoint to Google Drive: {dest_path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to upload checkpoint: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _cleanup_ghost_files(self, directory: str) -> None:\n",
    "        \"\"\"Delete macOS ghost files (._*) from directory.\"\"\"\n",
    "        count = 0\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.startswith(\"._\"):\n",
    "                file_path = os.path.join(directory, filename)\n",
    "                os.remove(file_path)\n",
    "                count += 1\n",
    "        if count > 0:\n",
    "            logger.info(f\"Cleaned up {count} macOS artifact files.\")\n",
    "\n",
    "\n",
    "class S3DataLoader(DataLoaderBase):\n",
    "    \"\"\"Data loader for AWS S3 (Production mode).\"\"\"\n",
    "    \n",
    "    def __init__(self, config: PiperConfig):\n",
    "        super().__init__(config)\n",
    "        if config.colab_mode:\n",
    "            raise ValueError(\"S3DataLoader requires AWS mode (config.colab_mode=False)\")\n",
    "        \n",
    "        self.s3_client = self._create_s3_client()\n",
    "    \n",
    "    def _create_s3_client(self):\n",
    "        \"\"\"Create S3 client with optional credentials.\"\"\"\n",
    "        try:\n",
    "            import boto3\n",
    "            from botocore.exceptions import ClientError\n",
    "        except ImportError:\n",
    "            raise ImportError(\"boto3 is required for S3 operations. Install with: pip install boto3\")\n",
    "        \n",
    "        kwargs = {'region_name': self.config.aws_region}\n",
    "        if self.config.aws_access_key_id and self.config.aws_secret_access_key:\n",
    "            kwargs['aws_access_key_id'] = self.config.aws_access_key_id\n",
    "            kwargs['aws_secret_access_key'] = self.config.aws_secret_access_key\n",
    "        \n",
    "        return boto3.client('s3', **kwargs)\n",
    "    \n",
    "    def _list_objects(self, prefix: str) -> List[str]:\n",
    "        \"\"\"List all objects under a prefix.\"\"\"\n",
    "        objects = []\n",
    "        paginator = self.s3_client.get_paginator('list_objects_v2')\n",
    "        for page in paginator.paginate(Bucket=self.config.s3_bucket, Prefix=prefix):\n",
    "            if 'Contents' in page:\n",
    "                objects.extend([obj['Key'] for obj in page['Contents']])\n",
    "        return objects\n",
    "    \n",
    "    def _download_file(self, s3_key: str, local_path: str) -> bool:\n",
    "        \"\"\"Download a single file from S3.\"\"\"\n",
    "        from botocore.exceptions import ClientError\n",
    "        try:\n",
    "            Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "            self.s3_client.download_file(self.config.s3_bucket, s3_key, local_path)\n",
    "            return True\n",
    "        except ClientError as e:\n",
    "            logger.error(f\"Failed to download {s3_key}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def download_dataset(self) -> int:\n",
    "        \"\"\"\n",
    "        Download dataset from S3 to local directory.\n",
    "        \n",
    "        Returns:\n",
    "            int: Number of files downloaded\n",
    "        \"\"\"\n",
    "        from tqdm import tqdm\n",
    "        \n",
    "        prefix = self.config.s3_dataset_prefix\n",
    "        objects = self._list_objects(prefix)\n",
    "        \n",
    "        if not objects:\n",
    "            raise FileNotFoundError(\n",
    "                f\"No objects found in s3://{self.config.s3_bucket}/{prefix}\\n\"\n",
    "                \"Please verify the S3 bucket and prefix are correct.\"\n",
    "            )\n",
    "        \n",
    "        downloaded = 0\n",
    "        for s3_key in tqdm(objects, desc=\"Downloading dataset from S3\"):\n",
    "            relative_path = s3_key[len(prefix):].lstrip('/')\n",
    "            local_path = os.path.join(self.config.local_dataset_dir, relative_path)\n",
    "            if self._download_file(s3_key, local_path):\n",
    "                downloaded += 1\n",
    "        \n",
    "        logger.info(f\"Downloaded {downloaded} files from S3\")\n",
    "        return downloaded\n",
    "    \n",
    "    def upload_checkpoint(self, local_path: str, remote_key: str) -> bool:\n",
    "        \"\"\"\n",
    "        Upload checkpoint to S3.\n",
    "        \n",
    "        Args:\n",
    "            local_path: Path to local checkpoint file\n",
    "            remote_key: S3 key (relative to s3_checkpoint_prefix)\n",
    "            \n",
    "        Returns:\n",
    "            bool: Success status\n",
    "        \"\"\"\n",
    "        from botocore.exceptions import ClientError\n",
    "        try:\n",
    "            s3_key = f\"{self.config.s3_checkpoint_prefix}/{remote_key}\"\n",
    "            self.s3_client.upload_file(local_path, self.config.s3_bucket, s3_key)\n",
    "            logger.info(f\"Uploaded checkpoint to s3://{self.config.s3_bucket}/{s3_key}\")\n",
    "            return True\n",
    "        except ClientError as e:\n",
    "            logger.error(f\"Failed to upload {local_path}: {e}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "def get_data_loader(config: PiperConfig) -> DataLoaderBase:\n",
    "    \"\"\"\n",
    "    Factory function to get the appropriate data loader based on configuration.\n",
    "    \n",
    "    Args:\n",
    "        config: PiperConfig instance\n",
    "        \n",
    "    Returns:\n",
    "        DataLoaderBase: Appropriate data loader instance\n",
    "    \"\"\"\n",
    "    if config.colab_mode:\n",
    "        return GoogleDriveDataLoader(config)\n",
    "    else:\n",
    "        return S3DataLoader(config)\n",
    "\n",
    "\n",
    "# Initialize data loader\n",
    "data_loader = get_data_loader(config)\n",
    "print(f\"âœ… Data loader initialized: {type(data_loader).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c6746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DOWNLOAD DATASET\n",
    "# =============================================================================\n",
    "# Download/copy dataset from remote storage to local directory.\n",
    "\n",
    "print(\"Downloading dataset...\")\n",
    "audio_count = data_loader.download_dataset()\n",
    "print(f\"\\nâœ… Dataset loaded: {audio_count} audio files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c8758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATASET STATISTICS UTILITY\n",
    "# =============================================================================\n",
    "# Calculate and display dataset statistics.\n",
    "\n",
    "import wave\n",
    "import datetime\n",
    "\n",
    "def get_dataset_duration(wav_path: str) -> Tuple[int, str]:\n",
    "    \"\"\"\n",
    "    Calculate total duration of all WAV files in a directory.\n",
    "    \n",
    "    Args:\n",
    "        wav_path: Path to directory containing WAV files\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[int, str]: (count of files, formatted duration string)\n",
    "    \"\"\"\n",
    "    total_duration = 0.0\n",
    "    total_count = 0\n",
    "    \n",
    "    if not os.path.exists(wav_path):\n",
    "        raise FileNotFoundError(f\"WAV directory not found: {wav_path}\")\n",
    "    \n",
    "    for file_name in os.listdir(wav_path):\n",
    "        if not file_name.endswith(\".wav\"):\n",
    "            continue\n",
    "        \n",
    "        full_path = os.path.join(wav_path, file_name)\n",
    "        try:\n",
    "            with wave.open(full_path, \"rb\") as wave_file:\n",
    "                frames = wave_file.getnframes()\n",
    "                rate = wave_file.getframerate()\n",
    "                duration = frames / float(rate)\n",
    "                total_duration += duration\n",
    "                total_count += 1\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Skipping bad file {file_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    duration_str = str(datetime.timedelta(seconds=round(total_duration, 0)))\n",
    "    return total_count, duration_str\n",
    "\n",
    "\n",
    "# Calculate and display dataset statistics\n",
    "audio_count, dataset_duration = get_dataset_duration(config.local_wavs_dir)\n",
    "print(f\"\\nðŸ“Š Dataset Statistics:\")\n",
    "print(f\"   Audio files: {audio_count}\")\n",
    "print(f\"   Total duration: {dataset_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aabd46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TEXT NORMALIZATION AND TRANSCRIPT PROCESSING\n",
    "# =============================================================================\n",
    "# Process transcript file with text normalization protocols.\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class TranscriptProcessor:\n",
    "    \"\"\"\n",
    "    Process transcript files with text normalization.\n",
    "    \n",
    "    Applies normalization protocols:\n",
    "    1. Orthographic expansion of non-standard words (currency, percentages, symbols)\n",
    "    2. Acronym handling (spacing out consecutive capitals)\n",
    "    3. Punctuation and prosodic boundaries (ensure terminal punctuation)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Supported transcript file names\n",
    "    TRANSCRIPT_FILES = [\"metadata.csv\", \"transcripts.txt\", \"transcript.txt\", \"metadata.txt\"]\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_line(text: str) -> str:\n",
    "        \"\"\"\n",
    "        Apply text normalization protocols to a single line of text.\n",
    "        \n",
    "        Args:\n",
    "            text: Input text line\n",
    "            \n",
    "        Returns:\n",
    "            str: Normalized text\n",
    "        \"\"\"\n",
    "        # --- Protocol 1: Orthographic Expansion ---\n",
    "        # Currency: $50 -> 50 dollars\n",
    "        text = re.sub(r'\\$(\\d+(?:\\.\\d+)?)', r'\\1 dollars', text)\n",
    "        \n",
    "        # Percentages: 50% -> 50 percent\n",
    "        text = re.sub(r'(\\d+)%', r'\\1 percent', text)\n",
    "        \n",
    "        # Ampersand: & -> and\n",
    "        text = text.replace('&', ' and ')\n",
    "        \n",
    "        # Plus sign: + -> plus\n",
    "        text = text.replace('+', ' plus ')\n",
    "        \n",
    "        # --- Protocol 2: Acronym Handling ---\n",
    "        # Space out consecutive capitals: \"IAS\" -> \"I A S\"\n",
    "        def space_acronym(match):\n",
    "            return \" \".join(match.group(1))\n",
    "        text = re.sub(r'\\b([A-Z]{2,})\\b', space_acronym, text)\n",
    "        \n",
    "        # --- Protocol 3: Punctuation and Prosodic Boundaries ---\n",
    "        text = text.strip()\n",
    "        if text and text[-1] not in ['.', '!', '?']:\n",
    "            text += '.'\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @classmethod\n",
    "    def process_file(cls, input_filename: str, output_filename: str) -> int:\n",
    "        \"\"\"\n",
    "        Process transcript file: read, normalize each line, and write to output.\n",
    "        \n",
    "        Args:\n",
    "            input_filename: Path to input transcript file\n",
    "            output_filename: Path to output processed file\n",
    "            \n",
    "        Returns:\n",
    "            int: Number of lines processed\n",
    "            \n",
    "        Raises:\n",
    "            FileNotFoundError: If input file doesn't exist\n",
    "            ValueError: If file contains no valid entries\n",
    "        \"\"\"\n",
    "        if not os.path.exists(input_filename):\n",
    "            raise FileNotFoundError(f\"Transcript file not found: {input_filename}\")\n",
    "        \n",
    "        lines_processed = 0\n",
    "        \n",
    "        with open(input_filename, 'r', encoding='utf-8') as infile, \\\n",
    "             open(output_filename, 'w', encoding='utf-8') as outfile:\n",
    "            \n",
    "            for line in infile:\n",
    "                if '|' in line:\n",
    "                    parts = line.strip().split('|', 1)\n",
    "                    if len(parts) == 2:\n",
    "                        file_id, original_text = parts\n",
    "                        cleaned_text = cls.clean_line(original_text)\n",
    "                        outfile.write(f\"{file_id}|{cleaned_text}\\n\")\n",
    "                        lines_processed += 1\n",
    "                    else:\n",
    "                        logger.warning(f\"Skipping malformed line (missing text after '|'): {line.strip()}\")\n",
    "                else:\n",
    "                    logger.warning(f\"Skipping non-ID|Text line: {line.strip()}\")\n",
    "        \n",
    "        if lines_processed == 0:\n",
    "            raise ValueError(\n",
    "                f\"No valid transcript entries found in {input_filename}.\\n\"\n",
    "                \"Expected format: filename.wav|transcript text\"\n",
    "            )\n",
    "        \n",
    "        logger.info(f\"Processed {lines_processed} lines for text normalization.\")\n",
    "        return lines_processed\n",
    "    \n",
    "    @classmethod\n",
    "    def find_and_process_transcript(cls, wavs_dir: str, output_dir: str) -> str:\n",
    "        \"\"\"\n",
    "        Find transcript file in wavs directory and process it.\n",
    "        \n",
    "        Args:\n",
    "            wavs_dir: Directory containing wavs and transcript file\n",
    "            output_dir: Directory to write processed metadata.csv\n",
    "            \n",
    "        Returns:\n",
    "            str: Path to processed metadata.csv\n",
    "            \n",
    "        Raises:\n",
    "            FileNotFoundError: If no transcript file is found\n",
    "        \"\"\"\n",
    "        source_path = None\n",
    "        \n",
    "        for tf in cls.TRANSCRIPT_FILES:\n",
    "            current_attempt = os.path.join(wavs_dir, tf)\n",
    "            if os.path.exists(current_attempt):\n",
    "                logger.info(f\"Found transcript file: {tf}\")\n",
    "                source_path = current_attempt\n",
    "                break\n",
    "        \n",
    "        if source_path is None:\n",
    "            raise FileNotFoundError(\n",
    "                f\"No transcript file found in {wavs_dir}.\\n\"\n",
    "                f\"Expected one of: {cls.TRANSCRIPT_FILES}\"\n",
    "            )\n",
    "        \n",
    "        output_path = os.path.join(output_dir, \"metadata.csv\")\n",
    "        logger.info(f\"Processing transcript: {source_path} -> {output_path}\")\n",
    "        cls.process_file(source_path, output_path)\n",
    "        \n",
    "        return output_path\n",
    "\n",
    "\n",
    "# Process transcript file\n",
    "metadata_csv_path = TranscriptProcessor.find_and_process_transcript(\n",
    "    config.local_wavs_dir,\n",
    "    config.local_dataset_dir\n",
    ")\n",
    "\n",
    "# Display processed metadata\n",
    "df_metadata = pd.read_csv(metadata_csv_path, sep='|', header=None, names=['filename', 'text'])\n",
    "print(f\"\\nâœ… Processed transcript: {len(df_metadata)} entries\")\n",
    "print(\"\\nðŸ“‹ Sample entries:\")\n",
    "display(df_metadata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb68aa30",
   "metadata": {},
   "source": [
    "# ðŸ¤– **5. Training**\n",
    "\n",
    "Configure and run the Piper TTS fine-tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0aa004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CHECKPOINT MANAGER\n",
    "# =============================================================================\n",
    "# Manage pretrained checkpoints from Hugging Face.\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "\n",
    "class CheckpointManager:\n",
    "    \"\"\"Manage model checkpoints for training and fine-tuning.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: PiperConfig):\n",
    "        self.config = config\n",
    "        self.pretrained_ckpt_path = os.path.join(config.base_dir, \"pretrained.ckpt\")\n",
    "    \n",
    "    def download_pretrained_checkpoint(self) -> str:\n",
    "        \"\"\"\n",
    "        Download pretrained checkpoint from Hugging Face.\n",
    "        \n",
    "        Returns:\n",
    "            str: Path to downloaded checkpoint\n",
    "            \n",
    "        Raises:\n",
    "            RuntimeError: If download fails\n",
    "        \"\"\"\n",
    "        if os.path.exists(self.pretrained_ckpt_path):\n",
    "            logger.info(f\"Pretrained checkpoint already exists: {self.pretrained_ckpt_path}\")\n",
    "            return self.pretrained_ckpt_path\n",
    "        \n",
    "        logger.info(\"Downloading pretrained checkpoint from Hugging Face...\")\n",
    "        \n",
    "        try:\n",
    "            downloaded_path = hf_hub_download(\n",
    "                repo_id=self.config.hf_checkpoint_repo,\n",
    "                filename=self.config.hf_checkpoint_path,\n",
    "                repo_type=\"dataset\",\n",
    "                local_dir=os.path.join(self.config.base_dir, \"checkpoints\"),\n",
    "            )\n",
    "            \n",
    "            # Also download the config for reference\n",
    "            hf_hub_download(\n",
    "                repo_id=self.config.hf_checkpoint_repo,\n",
    "                filename=self.config.hf_config_path,\n",
    "                repo_type=\"dataset\",\n",
    "                local_dir=os.path.join(self.config.base_dir, \"checkpoints\"),\n",
    "            )\n",
    "            \n",
    "            # Copy to expected location\n",
    "            shutil.copy(downloaded_path, self.pretrained_ckpt_path)\n",
    "            \n",
    "            logger.info(f\"Pretrained checkpoint downloaded to: {self.pretrained_ckpt_path}\")\n",
    "            return self.pretrained_ckpt_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to download pretrained checkpoint: {e}\")\n",
    "    \n",
    "    def find_latest_checkpoint(self, checkpoint_dir: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Find the latest checkpoint in a directory for resuming training.\n",
    "        \n",
    "        Args:\n",
    "            checkpoint_dir: Directory to search for checkpoints\n",
    "            \n",
    "        Returns:\n",
    "            Optional[str]: Path to latest checkpoint, or None if not found\n",
    "        \"\"\"\n",
    "        import glob\n",
    "        \n",
    "        # Look for 'last.ckpt' first\n",
    "        last_ckpt = os.path.join(checkpoint_dir, \"last.ckpt\")\n",
    "        if os.path.exists(last_ckpt):\n",
    "            return last_ckpt\n",
    "        \n",
    "        # Find most recent checkpoint by modification time\n",
    "        checkpoints = glob.glob(f\"{checkpoint_dir}/**/*.ckpt\", recursive=True)\n",
    "        if checkpoints:\n",
    "            latest = max(checkpoints, key=os.path.getmtime)\n",
    "            return latest\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def upgrade_checkpoint_for_cpu(self, ckpt_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Upgrade checkpoint for CPU compatibility (PyTorch Lightning upgrade).\n",
    "        \n",
    "        Args:\n",
    "            ckpt_path: Path to checkpoint file\n",
    "        \"\"\"\n",
    "        import torch\n",
    "        import pathlib\n",
    "        from argparse import Namespace\n",
    "        from lightning.pytorch.utilities.upgrade_checkpoint import _upgrade\n",
    "        \n",
    "        logger.info(f\"Upgrading checkpoint for compatibility: {ckpt_path}\")\n",
    "        \n",
    "        with torch.serialization.safe_globals([pathlib.PosixPath]):\n",
    "            args = Namespace(path=str(ckpt_path), extension=\".ckpt\", map_to_cpu=True)\n",
    "            _upgrade(args)\n",
    "        \n",
    "        logger.info(\"Checkpoint upgrade complete.\")\n",
    "\n",
    "\n",
    "# Initialize checkpoint manager\n",
    "ckpt_manager = CheckpointManager(config)\n",
    "print(\"âœ… Checkpoint manager initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e5735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DOWNLOAD PRETRAINED CHECKPOINT\n",
    "# =============================================================================\n",
    "# Download pretrained checkpoint from Hugging Face for fine-tuning.\n",
    "\n",
    "if config.use_pretrained and not config.resume_training:\n",
    "    pretrained_ckpt_path = ckpt_manager.download_pretrained_checkpoint()\n",
    "    \n",
    "    # Upgrade checkpoint for compatibility\n",
    "    ckpt_manager.upgrade_checkpoint_for_cpu(pretrained_ckpt_path)\n",
    "    \n",
    "    print(f\"\\nâœ… Pretrained checkpoint ready: {pretrained_ckpt_path}\")\n",
    "    \n",
    "elif config.resume_training:\n",
    "    print(\"Resume training mode - will look for existing checkpoint in output folder.\")\n",
    "else:\n",
    "    print(\"Training from scratch (no pretrained checkpoint).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb83e0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LAUNCH TENSORBOARD\n",
    "# =============================================================================\n",
    "# TensorBoard allows monitoring training progress in real-time.\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {config.local_output_dir}\n",
    "\n",
    "print(\"âœ… TensorBoard launched. Monitor training progress above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f536b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# START TRAINING\n",
    "# =============================================================================\n",
    "# Run the Piper TTS training process.\n",
    "\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# Change to piper directory\n",
    "%cd {config.piper_dir}\n",
    "\n",
    "# Prepare paths\n",
    "csv_path = metadata_csv_path\n",
    "config_path = f\"{config.local_output_dir}/{config.model_name}.json\"\n",
    "\n",
    "# Determine checkpoint path argument\n",
    "if config.resume_training:\n",
    "    # Look for existing checkpoint\n",
    "    checkpoints = glob.glob(f\"{config.local_output_dir}/lightning_logs/**/checkpoints/last.ckpt\", recursive=True)\n",
    "    if checkpoints:\n",
    "        # Sort by version number to get the latest\n",
    "        def get_version(path):\n",
    "            match = re.findall(r'version_(\\d+)', path)\n",
    "            return int(match[0]) if match else 0\n",
    "        latest_ckpt = sorted(checkpoints, key=get_version)[-1]\n",
    "        print(f\"Resuming from checkpoint: {latest_ckpt}\")\n",
    "        ckpt_path_arg = f'--ckpt_path \"{latest_ckpt}\"'\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"resume_training=True but no checkpoint found in {config.local_output_dir}/lightning_logs/\\n\"\n",
    "            \"Set resume_training=False to start fresh or ensure checkpoints exist.\"\n",
    "        )\n",
    "elif config.use_pretrained:\n",
    "    ckpt_url = f\"https://huggingface.co/datasets/{config.hf_checkpoint_repo}/blob/main/{config.hf_checkpoint_path}\"\n",
    "    print(f\"Fine-tuning from pretrained checkpoint: {ckpt_url}\")\n",
    "    ckpt_path_arg = f'--ckpt_path \"{ckpt_url}\"'\n",
    "else:\n",
    "    ckpt_path_arg = \"\"\n",
    "    print(\"Training from scratch (no checkpoint).\")\n",
    "\n",
    "# Build training command\n",
    "train_cmd = f\"\"\"\n",
    "python -m piper.train fit \\\\\n",
    "    --data.csv_path \"{csv_path}\" \\\\\n",
    "    --data.cache_dir \"{config.local_cache_dir}\" \\\\\n",
    "    --data.audio_dir \"{config.local_wavs_dir}\" \\\\\n",
    "    --data.espeak_voice \"{config.espeak_voice}\" \\\\\n",
    "    --data.config_path \"{config_path}\" \\\\\n",
    "    --data.voice_name \"{config.model_name}\" \\\\\n",
    "    --data.batch_size {config.batch_size} \\\\\n",
    "    --data.validation_split {config.validation_split} \\\\\n",
    "    --data.num_test_examples {config.num_test_examples} \\\\\n",
    "    --model.sample_rate {config.sample_rate} \\\\\n",
    "    --model.num_speakers {config.num_speakers} \\\\\n",
    "    --trainer.max_epochs {config.max_epochs} \\\\\n",
    "    --trainer.accelerator {config.device} \\\\\n",
    "    --trainer.devices 1 \\\\\n",
    "    --trainer.precision {config.precision} \\\\\n",
    "    --trainer.default_root_dir \"{config.local_output_dir}\" \\\\\n",
    "    --trainer.callbacks+=ModelCheckpoint \\\\\n",
    "    --trainer.callbacks.dirpath \"{config.local_output_dir}/checkpoints\" \\\\\n",
    "    --trainer.callbacks.filename \"piper-{{epoch:04d}}-{{step:08d}}\" \\\\\n",
    "    --trainer.callbacks.save_top_k 3 \\\\\n",
    "    --trainer.callbacks.monitor \"val_loss\" \\\\\n",
    "    --trainer.callbacks.save_last true \\\\\n",
    "    --trainer.callbacks.every_n_epochs {config.checkpoint_epochs} \\\\\n",
    "    --model.learning_rate {config.learning_rate} \\\\\n",
    "    {ckpt_path_arg}\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training command:\\n{train_cmd}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "!{train_cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee2445f",
   "metadata": {},
   "source": [
    "# ðŸ’¾ **6. Save Training Outputs**\n",
    "\n",
    "Save trained model checkpoints and configuration to remote storage (Google Drive or S3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87da57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SAVE TRAINING OUTPUTS TO REMOTE STORAGE\n",
    "# =============================================================================\n",
    "# Copy trained model, checkpoints, and logs to Google Drive or S3.\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "def save_training_outputs(config: PiperConfig, data_loader: DataLoaderBase) -> None:\n",
    "    \"\"\"\n",
    "    Save all training outputs to remote storage.\n",
    "    \n",
    "    Args:\n",
    "        config: PiperConfig instance\n",
    "        data_loader: DataLoader instance for upload operations\n",
    "    \"\"\"\n",
    "    if config.colab_mode:\n",
    "        # Create model-specific output directory in Google Drive\n",
    "        gdrive_model_dir = os.path.join(config.gdrive_output_path, config.model_name)\n",
    "        os.makedirs(gdrive_model_dir, exist_ok=True)\n",
    "        \n",
    "        files_to_copy = []\n",
    "        \n",
    "        # Copy last checkpoint\n",
    "        last_ckpt = f\"{config.local_output_dir}/checkpoints/last.ckpt\"\n",
    "        if os.path.exists(last_ckpt):\n",
    "            files_to_copy.append((last_ckpt, f\"{gdrive_model_dir}/last.ckpt\"))\n",
    "        else:\n",
    "            logger.warning(f\"Last checkpoint not found: {last_ckpt}\")\n",
    "        \n",
    "        # Copy config file\n",
    "        config_file = f\"{config.local_output_dir}/{config.model_name}.json\"\n",
    "        if os.path.exists(config_file):\n",
    "            files_to_copy.append((config_file, f\"{gdrive_model_dir}/{config.model_name}.json\"))\n",
    "        else:\n",
    "            logger.warning(f\"Config file not found: {config_file}\")\n",
    "        \n",
    "        # Copy lightning logs directory\n",
    "        lightning_logs = f\"{config.local_output_dir}/lightning_logs\"\n",
    "        if os.path.exists(lightning_logs):\n",
    "            shutil.copytree(lightning_logs, f\"{gdrive_model_dir}/lightning_logs\", dirs_exist_ok=True)\n",
    "            logger.info(f\"Copied lightning_logs to {gdrive_model_dir}\")\n",
    "        \n",
    "        # Copy individual files\n",
    "        for src, dst in files_to_copy:\n",
    "            if os.path.exists(src):\n",
    "                logger.info(f\"Copying {src} -> {dst}\")\n",
    "                shutil.copy(src, dst)\n",
    "        \n",
    "        # Display saved files\n",
    "        print(f\"\\nâœ… Model saved to Google Drive: {gdrive_model_dir}\")\n",
    "        print(\"\\nFiles saved:\")\n",
    "        for f in os.listdir(gdrive_model_dir):\n",
    "            fpath = os.path.join(gdrive_model_dir, f)\n",
    "            if os.path.isfile(fpath):\n",
    "                size_mb = os.path.getsize(fpath) / (1024 * 1024)\n",
    "                print(f\"  - {f} ({size_mb:.2f} MB)\")\n",
    "            else:\n",
    "                print(f\"  - {f}/ (directory)\")\n",
    "    \n",
    "    else:\n",
    "        # Upload to S3\n",
    "        last_ckpt = f\"{config.local_output_dir}/checkpoints/last.ckpt\"\n",
    "        if os.path.exists(last_ckpt):\n",
    "            data_loader.upload_checkpoint(last_ckpt, f\"{config.model_name}/last.ckpt\")\n",
    "        \n",
    "        config_file = f\"{config.local_output_dir}/{config.model_name}.json\"\n",
    "        if os.path.exists(config_file):\n",
    "            data_loader.upload_checkpoint(config_file, f\"{config.model_name}/{config.model_name}.json\")\n",
    "        \n",
    "        print(f\"\\nâœ… Model uploaded to S3: s3://{config.s3_bucket}/{config.s3_checkpoint_prefix}/{config.model_name}/\")\n",
    "\n",
    "\n",
    "# Save training outputs\n",
    "save_training_outputs(config, data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214ec3f0",
   "metadata": {},
   "source": [
    "# ðŸŽ§ **7. Test Model from Checkpoint**\n",
    "\n",
    "Test the trained model by loading from checkpoint and generating speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a76f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODEL TESTER CLASS\n",
    "# =============================================================================\n",
    "# Load model from checkpoint and generate test audio.\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "from IPython.display import Audio, display\n",
    "import sys\n",
    "\n",
    "# Add piper src to path\n",
    "if f\"{config.piper_dir}/src\" not in sys.path:\n",
    "    sys.path.append(f\"{config.piper_dir}/src\")\n",
    "\n",
    "from piper.train.vits.lightning import VitsModel\n",
    "from piper.phonemize_espeak import EspeakPhonemizer\n",
    "\n",
    "\n",
    "class ModelTester:\n",
    "    \"\"\"Test trained Piper TTS model from checkpoint.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: PiperConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.model_config = None\n",
    "        self.phonemizer = None\n",
    "    \n",
    "    def load_model(self, checkpoint_path: str, config_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Load model from checkpoint.\n",
    "        \n",
    "        Args:\n",
    "            checkpoint_path: Path to .ckpt file\n",
    "            config_path: Path to model config JSON\n",
    "        \"\"\"\n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            raise FileNotFoundError(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "        if not os.path.exists(config_path):\n",
    "            raise FileNotFoundError(f\"Config file not found: {config_path}\")\n",
    "        \n",
    "        # Load config\n",
    "        with open(config_path, 'r') as f:\n",
    "            self.model_config = json.load(f)\n",
    "        \n",
    "        # Load model\n",
    "        logger.info(f\"Loading model from {checkpoint_path}...\")\n",
    "        with torch.serialization.safe_globals([pathlib.PosixPath]):\n",
    "            self.model = VitsModel.load_from_checkpoint(checkpoint_path, map_location='cpu')\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            self.model.model_g.dec.remove_weight_norm()\n",
    "        \n",
    "        # Initialize phonemizer\n",
    "        self.phonemizer = EspeakPhonemizer()\n",
    "        \n",
    "        logger.info(\"Model loaded successfully.\")\n",
    "    \n",
    "    def synthesize(\n",
    "        self,\n",
    "        text: str,\n",
    "        noise_scale: float = 0.667,\n",
    "        length_scale: float = 1.0,\n",
    "        noise_scale_w: float = 0.8,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Synthesize speech from text.\n",
    "        \n",
    "        Args:\n",
    "            text: Text to synthesize\n",
    "            noise_scale: Noise scale for synthesis\n",
    "            length_scale: Length scale (1.0 = normal speed)\n",
    "            noise_scale_w: Noise scale for duration predictor\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Audio data\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model not loaded. Call load_model() first.\")\n",
    "        \n",
    "        # Phonemize text\n",
    "        phoneme_lists = self.phonemizer.phonemize(self.config.espeak_voice, text)\n",
    "        phonemes = []\n",
    "        for sentence in phoneme_lists:\n",
    "            phonemes.extend(sentence)\n",
    "        \n",
    "        # Map phonemes to IDs with interspersing\n",
    "        id_map = self.model_config[\"phoneme_id_map\"]\n",
    "        pad_id = id_map.get(\"^\", [0])[0]\n",
    "        \n",
    "        phoneme_ids = [pad_id]\n",
    "        missing_phonemes = []\n",
    "        \n",
    "        for p in phonemes:\n",
    "            if p in id_map:\n",
    "                phoneme_ids.extend(id_map[p])\n",
    "                phoneme_ids.append(pad_id)\n",
    "            else:\n",
    "                missing_phonemes.append(p)\n",
    "        \n",
    "        if missing_phonemes:\n",
    "            logger.warning(f\"Missing phonemes in config: {missing_phonemes}\")\n",
    "        \n",
    "        # Convert to tensors\n",
    "        sequence = torch.tensor(phoneme_ids, dtype=torch.long).unsqueeze(0)\n",
    "        sequence_lengths = torch.tensor([len(phoneme_ids)], dtype=torch.long)\n",
    "        \n",
    "        # Handle speaker ID\n",
    "        sid = None\n",
    "        if self.model_config.get(\"num_speakers\", 1) > 1:\n",
    "            sid = torch.tensor([0], dtype=torch.long)\n",
    "        \n",
    "        # Generate audio\n",
    "        with torch.no_grad():\n",
    "            audio = self.model.model_g.infer(\n",
    "                x=sequence,\n",
    "                x_lengths=sequence_lengths,\n",
    "                sid=sid,\n",
    "                noise_scale=noise_scale,\n",
    "                length_scale=length_scale,\n",
    "                noise_scale_w=noise_scale_w\n",
    "            )[0]\n",
    "        \n",
    "        # Process audio\n",
    "        audio_data = audio.squeeze().cpu().numpy()\n",
    "        audio_data = audio_data / np.max(np.abs(audio_data))\n",
    "        \n",
    "        return audio_data\n",
    "    \n",
    "    def synthesize_and_save(\n",
    "        self,\n",
    "        text: str,\n",
    "        output_path: str,\n",
    "        **kwargs\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Synthesize speech and save to WAV file.\n",
    "        \n",
    "        Args:\n",
    "            text: Text to synthesize\n",
    "            output_path: Output WAV file path\n",
    "            **kwargs: Additional arguments for synthesize()\n",
    "            \n",
    "        Returns:\n",
    "            str: Path to saved WAV file\n",
    "        \"\"\"\n",
    "        audio_data = self.synthesize(text, **kwargs)\n",
    "        sample_rate = self.model_config[\"audio\"][\"sample_rate\"]\n",
    "        \n",
    "        write(output_path, sample_rate, (audio_data * 32767).astype(np.int16))\n",
    "        logger.info(f\"Audio saved to {output_path}\")\n",
    "        \n",
    "        return output_path\n",
    "\n",
    "\n",
    "# Initialize tester\n",
    "model_tester = ModelTester(config)\n",
    "print(\"âœ… Model tester initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c56e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TEST SYNTHESIS FROM CHECKPOINT\n",
    "# =============================================================================\n",
    "# Generate test audio from trained model.\n",
    "\n",
    "# Configuration for testing\n",
    "TEST_TEXT = \"Hello, this is a test of the fine-tuned Piper text to speech model. Is this sounding correct?\"\n",
    "\n",
    "# Determine checkpoint and config paths\n",
    "if config.colab_mode:\n",
    "    gdrive_model_dir = os.path.join(config.gdrive_output_path, config.model_name)\n",
    "    test_checkpoint_path = f\"{gdrive_model_dir}/last.ckpt\"\n",
    "    test_config_path = f\"{gdrive_model_dir}/{config.model_name}.json\"\n",
    "else:\n",
    "    test_checkpoint_path = f\"{config.local_output_dir}/checkpoints/last.ckpt\"\n",
    "    test_config_path = f\"{config.local_output_dir}/{config.model_name}.json\"\n",
    "\n",
    "# Load model and synthesize\n",
    "try:\n",
    "    model_tester.load_model(test_checkpoint_path, test_config_path)\n",
    "    \n",
    "    print(f\"\\nSynthesizing: \\\"{TEST_TEXT}\\\"\")\n",
    "    audio_data = model_tester.synthesize(TEST_TEXT)\n",
    "    \n",
    "    sample_rate = model_tester.model_config[\"audio\"][\"sample_rate\"]\n",
    "    print(f\"Audio duration: {len(audio_data) / sample_rate:.2f} seconds\")\n",
    "    \n",
    "    # Display audio player\n",
    "    display(Audio(audio_data, rate=sample_rate))\n",
    "    \n",
    "    # Save to file\n",
    "    output_wav = f\"{config.local_output_dir}/test_output.wav\"\n",
    "    model_tester.synthesize_and_save(TEST_TEXT, output_wav)\n",
    "    print(f\"âœ… Test audio saved to: {output_wav}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"âš ï¸ Cannot test model: {e}\")\n",
    "    print(\"This is expected if training has not completed yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f334ef8",
   "metadata": {},
   "source": [
    "# ðŸ“¦ **8. Export to ONNX**\n",
    "\n",
    "Export the trained model to ONNX format for production inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90c106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ONNX Exporter Class\n",
    "# =============================================================================\n",
    "\n",
    "import shutil\n",
    "\n",
    "class ONNXExporter:\n",
    "    \"\"\"\n",
    "    Exports a trained Piper model checkpoint to ONNX format for production inference.\n",
    "    \n",
    "    This class handles:\n",
    "    - Finding the best or latest checkpoint\n",
    "    - Running the export subprocess\n",
    "    - Copying the voice configuration file\n",
    "    \n",
    "    Attributes:\n",
    "        config: PiperConfig instance with paths\n",
    "        checkpoint_path: Path to the checkpoint to export\n",
    "        output_dir: Directory for ONNX output\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: PiperConfig, checkpoint_path: str = None):\n",
    "        \"\"\"\n",
    "        Initialize the ONNX exporter.\n",
    "        \n",
    "        Args:\n",
    "            config: PiperConfig instance\n",
    "            checkpoint_path: Optional specific checkpoint path. If None, finds latest.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.output_dir = config.onnx_output_dir\n",
    "        self.checkpoint_path = checkpoint_path or self._find_checkpoint()\n",
    "    \n",
    "    def _find_checkpoint(self) -> str:\n",
    "        \"\"\"\n",
    "        Find the checkpoint to export.\n",
    "        \n",
    "        Priority:\n",
    "        1. Explicit checkpoint_path if provided\n",
    "        2. Best checkpoint (epoch=*-step=*.ckpt)\n",
    "        3. Latest checkpoint (last.ckpt)\n",
    "        \n",
    "        Returns:\n",
    "            Path to the checkpoint file\n",
    "            \n",
    "        Raises:\n",
    "            FileNotFoundError: If no checkpoint found\n",
    "        \"\"\"\n",
    "        import glob\n",
    "        \n",
    "        checkpoint_dir = self.config.training_output_dir\n",
    "        \n",
    "        # Look for best checkpoint first\n",
    "        best_checkpoints = glob.glob(os.path.join(checkpoint_dir, \"epoch=*-step=*.ckpt\"))\n",
    "        if best_checkpoints:\n",
    "            # Sort by modification time, get most recent\n",
    "            best_checkpoints.sort(key=os.path.getmtime, reverse=True)\n",
    "            return best_checkpoints[0]\n",
    "        \n",
    "        # Fall back to last.ckpt\n",
    "        last_ckpt = os.path.join(checkpoint_dir, \"last.ckpt\")\n",
    "        if os.path.exists(last_ckpt):\n",
    "            return last_ckpt\n",
    "        \n",
    "        raise FileNotFoundError(f\"No checkpoint found in {checkpoint_dir}\")\n",
    "    \n",
    "    def export(self) -> str:\n",
    "        \"\"\"\n",
    "        Export the checkpoint to ONNX format.\n",
    "        \n",
    "        Uses subprocess to run the Piper export script.\n",
    "        \n",
    "        Returns:\n",
    "            Path to the exported ONNX file\n",
    "            \n",
    "        Raises:\n",
    "            subprocess.CalledProcessError: If export fails\n",
    "        \"\"\"\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"ðŸ“¦ Exporting checkpoint to ONNX...\")\n",
    "        print(f\"   Checkpoint: {self.checkpoint_path}\")\n",
    "        print(f\"   Output dir: {self.output_dir}\")\n",
    "        \n",
    "        # Run export command\n",
    "        cmd = [\n",
    "            \"python\", \"-m\", \"piper.train.export_onnx\",\n",
    "            self.checkpoint_path,\n",
    "            self.output_dir\n",
    "        ]\n",
    "        \n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            print(f\"âŒ Export failed:\")\n",
    "            print(result.stderr)\n",
    "            raise subprocess.CalledProcessError(result.returncode, cmd, result.stdout, result.stderr)\n",
    "        \n",
    "        print(result.stdout)\n",
    "        \n",
    "        # Find the exported ONNX file\n",
    "        onnx_files = [f for f in os.listdir(self.output_dir) if f.endswith('.onnx')]\n",
    "        if onnx_files:\n",
    "            onnx_path = os.path.join(self.output_dir, onnx_files[0])\n",
    "            print(f\"âœ… ONNX model exported: {onnx_path}\")\n",
    "            return onnx_path\n",
    "        \n",
    "        raise FileNotFoundError(f\"No ONNX file found in {self.output_dir}\")\n",
    "    \n",
    "    def copy_config(self) -> str:\n",
    "        \"\"\"\n",
    "        Copy the voice configuration JSON to the output directory.\n",
    "        \n",
    "        The config.json file is required alongside the ONNX model for inference.\n",
    "        \n",
    "        Returns:\n",
    "            Path to the copied config file\n",
    "        \"\"\"\n",
    "        # Source config is in the training output directory\n",
    "        source_config = os.path.join(self.config.training_output_dir, \"config.json\")\n",
    "        \n",
    "        # If not there, try the dataset directory\n",
    "        if not os.path.exists(source_config):\n",
    "            source_config = os.path.join(self.config.dataset_dir, \"config.json\")\n",
    "        \n",
    "        if os.path.exists(source_config):\n",
    "            dest_config = os.path.join(self.output_dir, f\"{self.config.voice_name}.onnx.json\")\n",
    "            shutil.copy(source_config, dest_config)\n",
    "            print(f\"âœ… Config copied: {dest_config}\")\n",
    "            return dest_config\n",
    "        else:\n",
    "            print(\"âš ï¸ Warning: config.json not found, ONNX model may not work correctly\")\n",
    "            return None\n",
    "\n",
    "print(\"âœ… ONNXExporter class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c065e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Export Model to ONNX\n",
    "# =============================================================================\n",
    "\n",
    "try:\n",
    "    exporter = ONNXExporter(config)\n",
    "    onnx_path = exporter.export()\n",
    "    config_path = exporter.copy_config()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"ðŸ“¦ ONNX Export Complete!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"ONNX Model: {onnx_path}\")\n",
    "    if config_path:\n",
    "        print(f\"Config: {config_path}\")\n",
    "    print(\"\\nThese files can be used with Piper for inference.\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"âš ï¸ Export skipped: {e}\")\n",
    "    print(\"Train the model first to generate checkpoints.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa8104",
   "metadata": {},
   "source": [
    "# ðŸ§ª **9. Test ONNX Model**\n",
    "\n",
    "Test the exported ONNX model using ONNX Runtime for production-like inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23aada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ONNX Model Tester Class\n",
    "# =============================================================================\n",
    "\n",
    "class ONNXModelTester:\n",
    "    \"\"\"\n",
    "    Tests an exported ONNX model using ONNX Runtime.\n",
    "    \n",
    "    This provides production-like inference testing without PyTorch,\n",
    "    using only ONNX Runtime which is the recommended inference engine.\n",
    "    \n",
    "    Attributes:\n",
    "        config: PiperConfig instance\n",
    "        model_path: Path to the ONNX model file\n",
    "        config_path: Path to the voice config JSON\n",
    "        session: ONNX Runtime inference session\n",
    "        voice_config: Loaded voice configuration\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: PiperConfig, model_path: str = None):\n",
    "        \"\"\"\n",
    "        Initialize the ONNX model tester.\n",
    "        \n",
    "        Args:\n",
    "            config: PiperConfig instance\n",
    "            model_path: Optional explicit path to ONNX model\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.model_path = model_path or self._find_model()\n",
    "        self.config_path = self._find_config()\n",
    "        self.session = None\n",
    "        self.voice_config = None\n",
    "        self.phonemizer = None\n",
    "    \n",
    "    def _find_model(self) -> str:\n",
    "        \"\"\"Find the ONNX model file.\"\"\"\n",
    "        onnx_dir = self.config.onnx_output_dir\n",
    "        onnx_files = [f for f in os.listdir(onnx_dir) if f.endswith('.onnx')]\n",
    "        if onnx_files:\n",
    "            return os.path.join(onnx_dir, onnx_files[0])\n",
    "        raise FileNotFoundError(f\"No ONNX model found in {onnx_dir}\")\n",
    "    \n",
    "    def _find_config(self) -> str:\n",
    "        \"\"\"Find the voice configuration JSON.\"\"\"\n",
    "        onnx_dir = self.config.onnx_output_dir\n",
    "        json_files = [f for f in os.listdir(onnx_dir) if f.endswith('.json')]\n",
    "        if json_files:\n",
    "            return os.path.join(onnx_dir, json_files[0])\n",
    "        raise FileNotFoundError(f\"No config JSON found in {onnx_dir}\")\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"\n",
    "        Load the ONNX model and configuration.\n",
    "        \n",
    "        Creates an ONNX Runtime inference session and loads voice config.\n",
    "        \"\"\"\n",
    "        import onnxruntime as ort\n",
    "        import json\n",
    "        \n",
    "        print(f\"ðŸ“¦ Loading ONNX model: {self.model_path}\")\n",
    "        \n",
    "        # Create ONNX Runtime session\n",
    "        providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    "        self.session = ort.InferenceSession(self.model_path, providers=providers)\n",
    "        \n",
    "        # Load voice config\n",
    "        with open(self.config_path, 'r') as f:\n",
    "            self.voice_config = json.load(f)\n",
    "        \n",
    "        # Initialize phonemizer\n",
    "        from piper.phonemize_espeak import EspeakPhonemizer\n",
    "        self.phonemizer = EspeakPhonemizer(\n",
    "            voice=self.voice_config.get('espeak', {}).get('voice', 'en-us')\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Model loaded successfully\")\n",
    "        print(f\"   Sample rate: {self.voice_config.get('audio', {}).get('sample_rate', 22050)}\")\n",
    "        print(f\"   Phoneme type: {self.voice_config.get('phoneme_type', 'espeak')}\")\n",
    "    \n",
    "    def synthesize(self, text: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Synthesize audio from text using ONNX Runtime.\n",
    "        \n",
    "        Args:\n",
    "            text: Input text to synthesize\n",
    "            \n",
    "        Returns:\n",
    "            Audio samples as numpy array\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        from piper.phoneme_ids import phonemes_to_ids\n",
    "        \n",
    "        if self.session is None:\n",
    "            self.load_model()\n",
    "        \n",
    "        # Phonemize text\n",
    "        phonemes = self.phonemizer.phonemize(text)\n",
    "        \n",
    "        # Convert to IDs\n",
    "        phoneme_id_map = self.voice_config.get('phoneme_id_map', {})\n",
    "        phoneme_ids = phonemes_to_ids(phonemes, phoneme_id_map)\n",
    "        \n",
    "        # Prepare input\n",
    "        phoneme_ids_array = np.array([phoneme_ids], dtype=np.int64)\n",
    "        phoneme_ids_lengths = np.array([len(phoneme_ids)], dtype=np.int64)\n",
    "        scales = np.array([0.667, 1.0, 0.8], dtype=np.float32)  # noise, length, noise_w\n",
    "        \n",
    "        # Run inference\n",
    "        outputs = self.session.run(\n",
    "            None,\n",
    "            {\n",
    "                'input': phoneme_ids_array,\n",
    "                'input_lengths': phoneme_ids_lengths,\n",
    "                'scales': scales\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        audio = outputs[0].squeeze()\n",
    "        return audio\n",
    "    \n",
    "    def synthesize_and_play(self, text: str):\n",
    "        \"\"\"\n",
    "        Synthesize and play audio in notebook.\n",
    "        \n",
    "        Args:\n",
    "            text: Text to synthesize\n",
    "        \"\"\"\n",
    "        from IPython.display import Audio, display\n",
    "        \n",
    "        audio = self.synthesize(text)\n",
    "        sample_rate = self.voice_config.get('audio', {}).get('sample_rate', 22050)\n",
    "        \n",
    "        print(f\"ðŸŽ¤ Text: '{text}'\")\n",
    "        display(Audio(audio, rate=sample_rate))\n",
    "    \n",
    "    def synthesize_and_save(self, text: str, output_path: str):\n",
    "        \"\"\"\n",
    "        Synthesize and save audio to file.\n",
    "        \n",
    "        Args:\n",
    "            text: Text to synthesize\n",
    "            output_path: Path to save WAV file\n",
    "        \"\"\"\n",
    "        import wave\n",
    "        import struct\n",
    "        \n",
    "        audio = self.synthesize(text)\n",
    "        sample_rate = self.voice_config.get('audio', {}).get('sample_rate', 22050)\n",
    "        \n",
    "        # Normalize and convert to 16-bit PCM\n",
    "        audio = audio / np.max(np.abs(audio))\n",
    "        audio_int16 = (audio * 32767).astype(np.int16)\n",
    "        \n",
    "        # Save as WAV\n",
    "        with wave.open(output_path, 'wb') as wav_file:\n",
    "            wav_file.setnchannels(1)\n",
    "            wav_file.setsampwidth(2)\n",
    "            wav_file.setframerate(sample_rate)\n",
    "            wav_file.writeframes(audio_int16.tobytes())\n",
    "        \n",
    "        print(f\"âœ… Saved: {output_path}\")\n",
    "\n",
    "print(\"âœ… ONNXModelTester class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f7157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Test ONNX Model\n",
    "# =============================================================================\n",
    "\n",
    "try:\n",
    "    # Initialize ONNX tester\n",
    "    onnx_tester = ONNXModelTester(config)\n",
    "    onnx_tester.load_model()\n",
    "    \n",
    "    # Test phrases\n",
    "    test_phrases = [\n",
    "        \"Hello, this is a test of the fine-tuned Indian English voice model.\",\n",
    "        \"The ONNX export was successful and the model is ready for production.\",\n",
    "        \"NavGurukul is transforming lives through technology education.\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"ðŸ§ª Testing ONNX Model\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, phrase in enumerate(test_phrases, 1):\n",
    "        print(f\"\\n--- Test {i} ---\")\n",
    "        onnx_tester.synthesize_and_play(phrase)\n",
    "        \n",
    "        # Also save to file\n",
    "        output_file = os.path.join(config.onnx_output_dir, f\"onnx_test_{i}.wav\")\n",
    "        onnx_tester.synthesize_and_save(phrase, output_file)\n",
    "    \n",
    "    print(\"\\nâœ… ONNX model testing complete!\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"âš ï¸ ONNX testing skipped: {e}\")\n",
    "    print(\"Export the model to ONNX first.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error testing ONNX model: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150a6202",
   "metadata": {},
   "source": [
    "# âœ… **Summary**\n",
    "\n",
    "## Pipeline Complete!\n",
    "\n",
    "This notebook provides a complete, production-ready pipeline for fine-tuning Piper TTS models with Indian English voices.\n",
    "\n",
    "### ðŸ“ Output Files\n",
    "\n",
    "| File | Location | Description |\n",
    "|------|----------|-------------|\n",
    "| Checkpoints | `{training_output_dir}/*.ckpt` | PyTorch Lightning checkpoints |\n",
    "| ONNX Model | `{onnx_output_dir}/*.onnx` | Exported ONNX model for inference |\n",
    "| Config | `{onnx_output_dir}/*.onnx.json` | Voice configuration |\n",
    "| Test Audio | `{onnx_output_dir}/test_*.wav` | Generated test samples |\n",
    "\n",
    "### ðŸ”„ Mode Comparison\n",
    "\n",
    "| Feature | COLAB Mode | AWS Mode |\n",
    "|---------|-----------|----------|\n",
    "| Data Source | Google Drive | AWS S3 |\n",
    "| Storage Mount | `/content/drive` | `/content/s3_data` |\n",
    "| GPU | Colab GPU | EC2 GPU |\n",
    "| Best For | Development/Testing | Production Training |\n",
    "\n",
    "### ðŸ—ï¸ Key Classes\n",
    "\n",
    "1. **PiperConfig** - Centralized configuration with validation\n",
    "2. **DataLoaderBase** - Abstract base for data loading (Google Drive / S3)\n",
    "3. **TranscriptProcessor** - Text normalization and cleaning\n",
    "4. **CheckpointManager** - Pretrained model download and management\n",
    "5. **ModelTester** - Checkpoint-based inference testing\n",
    "6. **ONNXExporter** - Export to ONNX format\n",
    "7. **ONNXModelTester** - Production-like ONNX inference\n",
    "\n",
    "### ðŸš€ Next Steps\n",
    "\n",
    "1. Deploy the ONNX model using Piper's inference engine\n",
    "2. Integrate with your application's TTS pipeline\n",
    "3. Fine-tune hyperparameters for better voice quality\n",
    "4. Add more training data for improved results\n",
    "\n",
    "---\n",
    "\n",
    "**Created by:** NavGurukul AI Team  \n",
    "**Repository:** piper1-gpl"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
