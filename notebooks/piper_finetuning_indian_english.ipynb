{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Piper TTS Fine-Tuning: Indian English Voice\n",
    "\n",
    "This notebook provides a complete pipeline for fine-tuning the Piper TTS `en_US/hfc_female/medium` model using the IISc SPICOR English dataset to create an Indian English voice.\n",
    "\n",
    "**Compatible with:** Google Colab and AWS SageMaker\n",
    "\n",
    "## Overview\n",
    "1. Environment Setup\n",
    "2. Configuration\n",
    "3. Dataset ETL from S3\n",
    "4. Data Preprocessing\n",
    "5. Model Fine-Tuning with Checkpointing\n",
    "6. Resume Training from Checkpoint\n",
    "7. ONNX Export for Web Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect environment (Colab vs SageMaker)\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def detect_environment():\n",
    "    \"\"\"Detect if running on Colab or SageMaker.\"\"\"\n",
    "    if 'google.colab' in sys.modules:\n",
    "        return 'colab'\n",
    "    elif os.path.exists('/opt/ml'):\n",
    "        return 'sagemaker'\n",
    "    else:\n",
    "        return 'local'\n",
    "\n",
    "ENV = detect_environment()\n",
    "print(f\"Running on: {ENV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install system dependencies\n",
    "if ENV == 'colab':\n",
    "    !apt-get update -qq\n",
    "    !apt-get install -y -qq build-essential cmake ninja-build espeak-ng\n",
    "elif ENV == 'sagemaker':\n",
    "    !sudo yum install -y espeak-ng cmake ninja-build gcc gcc-c++ make\n",
    "else:\n",
    "    print(\"Please ensure build-essential, cmake, ninja-build, and espeak-ng are installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone Piper repository and install\n",
    "!git clone https://github.com/OHF-voice/piper1-gpl.git /tmp/piper1-gpl\n",
    "%cd /tmp/piper1-gpl\n",
    "!pip install -e .[train] --quiet\n",
    "!./build_monotonic_align.sh\n",
    "!python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional dependencies\n",
    "!pip install boto3 huggingface_hub tqdm soundfile --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Configure all paths and parameters. Replace placeholder values with your actual settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration for Piper fine-tuning pipeline.\"\"\"\n",
    "    \n",
    "    # ==================== PLACEHOLDERS - UPDATE THESE ====================\n",
    "    \n",
    "    # S3 Configuration\n",
    "    s3_bucket: str = \"YOUR_S3_BUCKET_NAME\"  # e.g., \"my-tts-training-bucket\"\n",
    "    s3_dataset_prefix: str = \"datasets/spicor/\"  # Path to SPICOR dataset in S3\n",
    "    s3_checkpoint_prefix: str = \"checkpoints/piper-indian-english/\"  # Where to save checkpoints\n",
    "    aws_region: str = \"us-east-1\"  # Your AWS region\n",
    "    \n",
    "    # HuggingFace Configuration\n",
    "    hf_checkpoint_repo: str = \"rhasspy/piper-checkpoints\"\n",
    "    hf_checkpoint_path: str = \"en/en_US/hfc_female/medium/epoch=2868-step=1575188.ckpt\"\n",
    "    hf_model_repo: str = \"rhasspy/piper-voices\"  # Alternative: \"the-vedantic-coder/text-to-speech-en-US-web\"\n",
    "    \n",
    "    # ==================== LOCAL PATHS ====================\n",
    "    \n",
    "    # Base directories\n",
    "    base_dir: Path = field(default_factory=lambda: Path(\"/tmp/piper-training\"))\n",
    "    \n",
    "    @property\n",
    "    def data_dir(self) -> Path:\n",
    "        return self.base_dir / \"data\"\n",
    "    \n",
    "    @property\n",
    "    def audio_dir(self) -> Path:\n",
    "        return self.data_dir / \"audio\"\n",
    "    \n",
    "    @property\n",
    "    def cache_dir(self) -> Path:\n",
    "        return self.base_dir / \"cache\"\n",
    "    \n",
    "    @property\n",
    "    def checkpoint_dir(self) -> Path:\n",
    "        return self.base_dir / \"checkpoints\"\n",
    "    \n",
    "    @property\n",
    "    def output_dir(self) -> Path:\n",
    "        return self.base_dir / \"output\"\n",
    "    \n",
    "    @property\n",
    "    def csv_path(self) -> Path:\n",
    "        return self.data_dir / \"metadata.csv\"\n",
    "    \n",
    "    @property\n",
    "    def config_path(self) -> Path:\n",
    "        return self.output_dir / \"config.json\"\n",
    "    \n",
    "    @property\n",
    "    def pretrained_checkpoint_path(self) -> Path:\n",
    "        return self.checkpoint_dir / \"pretrained.ckpt\"\n",
    "    \n",
    "    # ==================== TRAINING PARAMETERS ====================\n",
    "    \n",
    "    # Voice settings\n",
    "    voice_name: str = \"en_IN-spicor-medium\"\n",
    "    espeak_voice: str = \"en-us\"  # Use en-us for Indian English phonemization\n",
    "    sample_rate: int = 22050\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    batch_size: int = 16  # Adjust based on GPU memory (8-32 typical)\n",
    "    learning_rate: float = 1e-4  # Lower LR for fine-tuning\n",
    "    max_epochs: int = 500\n",
    "    \n",
    "    # Checkpointing\n",
    "    checkpoint_every_n_steps: int = 500  # Save checkpoint every N steps\n",
    "    checkpoint_every_n_epochs: int = 10  # Also save every N epochs\n",
    "    keep_last_n_checkpoints: int = 5  # Number of recent checkpoints to keep\n",
    "    \n",
    "    # Resume training\n",
    "    resume_from_checkpoint: Optional[str] = None  # Path to checkpoint to resume from\n",
    "    \n",
    "    # Hardware\n",
    "    num_workers: int = 4\n",
    "    accelerator: str = \"auto\"  # \"gpu\", \"cpu\", or \"auto\"\n",
    "    devices: int = 1  # Number of GPUs\n",
    "    precision: str = \"16-mixed\"  # Use mixed precision for faster training\n",
    "    \n",
    "    def create_directories(self):\n",
    "        \"\"\"Create all necessary directories.\"\"\"\n",
    "        for path in [self.data_dir, self.audio_dir, self.cache_dir, \n",
    "                     self.checkpoint_dir, self.output_dir]:\n",
    "            path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "config.create_directories()\n",
    "print(f\"Configuration initialized. Base directory: {config.base_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset ETL from S3\n",
    "\n",
    "Download and process the SPICOR English dataset from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "class S3DatasetLoader:\n",
    "    \"\"\"Handles dataset loading from S3.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.s3_client = boto3.client('s3', region_name=config.aws_region)\n",
    "    \n",
    "    def list_audio_files(self) -> list:\n",
    "        \"\"\"List all audio files in the S3 dataset prefix.\"\"\"\n",
    "        audio_files = []\n",
    "        paginator = self.s3_client.get_paginator('list_objects_v2')\n",
    "        \n",
    "        for page in paginator.paginate(Bucket=self.config.s3_bucket, \n",
    "                                        Prefix=self.config.s3_dataset_prefix):\n",
    "            for obj in page.get('Contents', []):\n",
    "                key = obj['Key']\n",
    "                if key.endswith(('.wav', '.mp3', '.flac')):\n",
    "                    audio_files.append(key)\n",
    "        \n",
    "        return audio_files\n",
    "    \n",
    "    def download_file(self, s3_key: str, local_path: Path) -> bool:\n",
    "        \"\"\"Download a single file from S3.\"\"\"\n",
    "        try:\n",
    "            local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            self.s3_client.download_file(\n",
    "                self.config.s3_bucket, s3_key, str(local_path)\n",
    "            )\n",
    "            return True\n",
    "        except ClientError as e:\n",
    "            print(f\"Error downloading {s3_key}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def download_dataset(self, max_files: Optional[int] = None) -> int:\n",
    "        \"\"\"Download the entire dataset from S3.\"\"\"\n",
    "        audio_files = self.list_audio_files()\n",
    "        \n",
    "        if max_files:\n",
    "            audio_files = audio_files[:max_files]\n",
    "        \n",
    "        downloaded = 0\n",
    "        for s3_key in tqdm(audio_files, desc=\"Downloading audio files\"):\n",
    "            filename = Path(s3_key).name\n",
    "            local_path = self.config.audio_dir / filename\n",
    "            \n",
    "            if local_path.exists():\n",
    "                downloaded += 1\n",
    "                continue\n",
    "            \n",
    "            if self.download_file(s3_key, local_path):\n",
    "                downloaded += 1\n",
    "        \n",
    "        return downloaded\n",
    "    \n",
    "    def download_metadata(self, metadata_key: str) -> dict:\n",
    "        \"\"\"Download and parse metadata JSON from S3.\"\"\"\n",
    "        local_path = self.config.data_dir / \"metadata.json\"\n",
    "        self.download_file(metadata_key, local_path)\n",
    "        \n",
    "        with open(local_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    def upload_checkpoint(self, local_path: Path, s3_key: str) -> bool:\n",
    "        \"\"\"Upload a checkpoint to S3 for backup.\"\"\"\n",
    "        try:\n",
    "            self.s3_client.upload_file(\n",
    "                str(local_path), self.config.s3_bucket, s3_key\n",
    "            )\n",
    "            return True\n",
    "        except ClientError as e:\n",
    "            print(f\"Error uploading checkpoint: {e}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize S3 loader and download dataset\n",
    "# Uncomment and run when ready to download from S3\n",
    "\n",
    "# s3_loader = S3DatasetLoader(config)\n",
    "# num_downloaded = s3_loader.download_dataset()\n",
    "# print(f\"Downloaded {num_downloaded} audio files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "Process the SPICOR dataset into the format required by Piper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "import re\n",
    "\n",
    "class DataPreprocessor:\n",
    "    \"\"\"Preprocesses audio data for Piper training.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "    \n",
    "    def parse_spicor_metadata(self, metadata_path: Path) -> List[Tuple[str, str]]:\n",
    "        \"\"\"\n",
    "        Parse SPICOR dataset metadata.\n",
    "        \n",
    "        SPICOR format varies - adjust this method based on actual format.\n",
    "        Expected: Returns list of (audio_filename, transcript) tuples.\n",
    "        \"\"\"\n",
    "        entries = []\n",
    "        \n",
    "        # Handle different possible metadata formats\n",
    "        if metadata_path.suffix == '.json':\n",
    "            import json\n",
    "            with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                for item in data:\n",
    "                    audio_file = item.get('audio', item.get('file', item.get('path')))\n",
    "                    text = item.get('text', item.get('transcript', item.get('sentence')))\n",
    "                    if audio_file and text:\n",
    "                        entries.append((audio_file, text))\n",
    "        \n",
    "        elif metadata_path.suffix == '.csv':\n",
    "            with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "                reader = csv.reader(f, delimiter='|')\n",
    "                for row in reader:\n",
    "                    if len(row) >= 2:\n",
    "                        entries.append((row[0], row[-1]))\n",
    "        \n",
    "        elif metadata_path.suffix == '.txt':\n",
    "            with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split('|')\n",
    "                    if len(parts) >= 2:\n",
    "                        entries.append((parts[0], parts[-1]))\n",
    "        \n",
    "        return entries\n",
    "    \n",
    "    def normalize_text(self, text: str) -> str:\n",
    "        \"\"\"Normalize text for TTS training.\"\"\"\n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        # Basic normalization\n",
    "        text = text.strip()\n",
    "        return text\n",
    "    \n",
    "    def validate_audio(self, audio_path: Path, min_duration: float = 0.5, \n",
    "                       max_duration: float = 15.0) -> bool:\n",
    "        \"\"\"Validate audio file for training.\"\"\"\n",
    "        try:\n",
    "            info = sf.info(str(audio_path))\n",
    "            duration = info.duration\n",
    "            return min_duration <= duration <= max_duration\n",
    "        except Exception as e:\n",
    "            print(f\"Error validating {audio_path}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def resample_audio(self, input_path: Path, output_path: Path, \n",
    "                       target_sr: int = 22050) -> bool:\n",
    "        \"\"\"Resample audio to target sample rate.\"\"\"\n",
    "        try:\n",
    "            audio, sr = librosa.load(str(input_path), sr=target_sr, mono=True)\n",
    "            sf.write(str(output_path), audio, target_sr)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error resampling {input_path}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def create_metadata_csv(self, entries: List[Tuple[str, str]]) -> int:\n",
    "        \"\"\"\n",
    "        Create Piper-compatible metadata CSV.\n",
    "        \n",
    "        Format: audio_filename|text\n",
    "        \"\"\"\n",
    "        valid_entries = 0\n",
    "        \n",
    "        with open(self.config.csv_path, 'w', encoding='utf-8', newline='') as f:\n",
    "            writer = csv.writer(f, delimiter='|')\n",
    "            \n",
    "            for audio_file, text in tqdm(entries, desc=\"Processing entries\"):\n",
    "                audio_path = self.config.audio_dir / audio_file\n",
    "                \n",
    "                # Check if audio file exists\n",
    "                if not audio_path.exists():\n",
    "                    # Try with .wav extension\n",
    "                    audio_path = self.config.audio_dir / f\"{audio_file}.wav\"\n",
    "                    if not audio_path.exists():\n",
    "                        continue\n",
    "                \n",
    "                # Validate audio\n",
    "                if not self.validate_audio(audio_path):\n",
    "                    continue\n",
    "                \n",
    "                # Normalize text\n",
    "                normalized_text = self.normalize_text(text)\n",
    "                if not normalized_text:\n",
    "                    continue\n",
    "                \n",
    "                # Write entry\n",
    "                writer.writerow([audio_path.name, normalized_text])\n",
    "                valid_entries += 1\n",
    "        \n",
    "        return valid_entries\n",
    "    \n",
    "    def process_dataset(self, metadata_path: Path) -> int:\n",
    "        \"\"\"Full preprocessing pipeline.\"\"\"\n",
    "        print(\"Parsing metadata...\")\n",
    "        entries = self.parse_spicor_metadata(metadata_path)\n",
    "        print(f\"Found {len(entries)} entries in metadata\")\n",
    "        \n",
    "        print(\"Creating metadata CSV...\")\n",
    "        valid_entries = self.create_metadata_csv(entries)\n",
    "        print(f\"Created metadata CSV with {valid_entries} valid entries\")\n",
    "        \n",
    "        return valid_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample metadata for testing (replace with actual SPICOR metadata path)\n",
    "# preprocessor = DataPreprocessor(config)\n",
    "# num_entries = preprocessor.process_dataset(config.data_dir / \"spicor_metadata.json\")\n",
    "# print(f\"Processed {num_entries} training samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download Pre-trained Checkpoint\n",
    "\n",
    "Download the base checkpoint from HuggingFace for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download, snapshot_download\n",
    "\n",
    "class CheckpointManager:\n",
    "    \"\"\"Manages model checkpoints.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "    \n",
    "    def download_pretrained_checkpoint(self) -> Path:\n",
    "        \"\"\"Download pre-trained checkpoint from HuggingFace.\"\"\"\n",
    "        print(f\"Downloading checkpoint from {self.config.hf_checkpoint_repo}...\")\n",
    "        \n",
    "        checkpoint_path = hf_hub_download(\n",
    "            repo_id=self.config.hf_checkpoint_repo,\n",
    "            filename=self.config.hf_checkpoint_path,\n",
    "            repo_type=\"dataset\",\n",
    "            local_dir=self.config.checkpoint_dir,\n",
    "            local_dir_use_symlinks=False\n",
    "        )\n",
    "        \n",
    "        # Copy to standard location\n",
    "        import shutil\n",
    "        shutil.copy(checkpoint_path, self.config.pretrained_checkpoint_path)\n",
    "        \n",
    "        print(f\"Checkpoint saved to: {self.config.pretrained_checkpoint_path}\")\n",
    "        return self.config.pretrained_checkpoint_path\n",
    "    \n",
    "    def get_latest_checkpoint(self) -> Optional[Path]:\n",
    "        \"\"\"Find the latest training checkpoint.\"\"\"\n",
    "        checkpoints = list(self.config.checkpoint_dir.glob(\"epoch=*-step=*.ckpt\"))\n",
    "        \n",
    "        if not checkpoints:\n",
    "            return None\n",
    "        \n",
    "        # Sort by modification time\n",
    "        checkpoints.sort(key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "        return checkpoints[0]\n",
    "    \n",
    "    def cleanup_old_checkpoints(self, keep_n: int = 5):\n",
    "        \"\"\"Remove old checkpoints, keeping the N most recent.\"\"\"\n",
    "        checkpoints = list(self.config.checkpoint_dir.glob(\"epoch=*-step=*.ckpt\"))\n",
    "        checkpoints.sort(key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "        \n",
    "        for ckpt in checkpoints[keep_n:]:\n",
    "            print(f\"Removing old checkpoint: {ckpt.name}\")\n",
    "            ckpt.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pre-trained checkpoint\n",
    "checkpoint_manager = CheckpointManager(config)\n",
    "pretrained_ckpt = checkpoint_manager.download_pretrained_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Fine-Tuning with Checkpointing\n",
    "\n",
    "Fine-tune the Piper model with frequent checkpointing for fault tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add piper to path\n",
    "sys.path.insert(0, '/tmp/piper1-gpl/src')\n",
    "\n",
    "from piper.train.vits.lightning import VitsModel\n",
    "from piper.train.vits.dataset import VitsDataModule\n",
    "\n",
    "class PiperTrainer:\n",
    "    \"\"\"Handles Piper model training with checkpointing.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.trainer = None\n",
    "        self.model = None\n",
    "        self.data_module = None\n",
    "    \n",
    "    def setup_data_module(self) -> VitsDataModule:\n",
    "        \"\"\"Initialize the data module.\"\"\"\n",
    "        self.data_module = VitsDataModule(\n",
    "            csv_path=self.config.csv_path,\n",
    "            cache_dir=self.config.cache_dir,\n",
    "            espeak_voice=self.config.espeak_voice,\n",
    "            config_path=self.config.config_path,\n",
    "            voice_name=self.config.voice_name,\n",
    "            sample_rate=self.config.sample_rate,\n",
    "            audio_dir=self.config.audio_dir,\n",
    "            batch_size=self.config.batch_size,\n",
    "            num_workers=self.config.num_workers,\n",
    "        )\n",
    "        return self.data_module\n",
    "    \n",
    "    def setup_callbacks(self) -> list:\n",
    "        \"\"\"Setup training callbacks for checkpointing.\"\"\"\n",
    "        callbacks = [\n",
    "            # Save checkpoint every N steps\n",
    "            ModelCheckpoint(\n",
    "                dirpath=self.config.checkpoint_dir,\n",
    "                filename=\"{epoch}-{step}-{val_loss:.4f}\",\n",
    "                save_top_k=self.config.keep_last_n_checkpoints,\n",
    "                monitor=\"val_loss\",\n",
    "                mode=\"min\",\n",
    "                every_n_train_steps=self.config.checkpoint_every_n_steps,\n",
    "                save_last=True,\n",
    "            ),\n",
    "            # Save checkpoint every N epochs\n",
    "            ModelCheckpoint(\n",
    "                dirpath=self.config.checkpoint_dir,\n",
    "                filename=\"epoch-{epoch}\",\n",
    "                save_top_k=-1,  # Keep all epoch checkpoints\n",
    "                every_n_epochs=self.config.checkpoint_every_n_epochs,\n",
    "            ),\n",
    "            # Monitor learning rate\n",
    "            LearningRateMonitor(logging_interval=\"step\"),\n",
    "            # Early stopping (optional)\n",
    "            EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=50,\n",
    "                mode=\"min\",\n",
    "                verbose=True,\n",
    "            ),\n",
    "        ]\n",
    "        return callbacks\n",
    "    \n",
    "    def setup_trainer(self, resume_checkpoint: Optional[Path] = None) -> L.Trainer:\n",
    "        \"\"\"Setup PyTorch Lightning trainer.\"\"\"\n",
    "        logger = TensorBoardLogger(\n",
    "            save_dir=self.config.output_dir,\n",
    "            name=\"piper_finetune\",\n",
    "            version=\"indian_english\"\n",
    "        )\n",
    "        \n",
    "        self.trainer = L.Trainer(\n",
    "            accelerator=self.config.accelerator,\n",
    "            devices=self.config.devices,\n",
    "            precision=self.config.precision,\n",
    "            max_epochs=self.config.max_epochs,\n",
    "            callbacks=self.setup_callbacks(),\n",
    "            logger=logger,\n",
    "            log_every_n_steps=10,\n",
    "            val_check_interval=0.25,  # Validate 4 times per epoch\n",
    "            gradient_clip_val=1.0,\n",
    "            enable_progress_bar=True,\n",
    "        )\n",
    "        \n",
    "        return self.trainer\n",
    "    \n",
    "    def load_model(self, checkpoint_path: Optional[Path] = None) -> VitsModel:\n",
    "        \"\"\"Load model from checkpoint or create new.\"\"\"\n",
    "        if checkpoint_path and checkpoint_path.exists():\n",
    "            print(f\"Loading model from checkpoint: {checkpoint_path}\")\n",
    "            self.model = VitsModel.load_from_checkpoint(\n",
    "                checkpoint_path,\n",
    "                map_location=\"cpu\",\n",
    "                learning_rate=self.config.learning_rate,\n",
    "            )\n",
    "        else:\n",
    "            print(\"Creating new model...\")\n",
    "            self.model = VitsModel(\n",
    "                batch_size=self.config.batch_size,\n",
    "                sample_rate=self.config.sample_rate,\n",
    "                learning_rate=self.config.learning_rate,\n",
    "            )\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def train(self, resume_from: Optional[Path] = None):\n",
    "        \"\"\"\n",
    "        Run training with optional resume from checkpoint.\n",
    "        \n",
    "        Args:\n",
    "            resume_from: Path to checkpoint to resume from.\n",
    "                        If None, starts fresh from pretrained checkpoint.\n",
    "        \"\"\"\n",
    "        # Setup data\n",
    "        self.setup_data_module()\n",
    "        \n",
    "        # Setup trainer\n",
    "        self.setup_trainer()\n",
    "        \n",
    "        # Determine checkpoint to use\n",
    "        ckpt_path = None\n",
    "        if resume_from and resume_from.exists():\n",
    "            print(f\"Resuming training from: {resume_from}\")\n",
    "            ckpt_path = str(resume_from)\n",
    "            self.model = self.load_model(resume_from)\n",
    "        elif self.config.pretrained_checkpoint_path.exists():\n",
    "            print(f\"Fine-tuning from pretrained: {self.config.pretrained_checkpoint_path}\")\n",
    "            ckpt_path = str(self.config.pretrained_checkpoint_path)\n",
    "            self.model = self.load_model(self.config.pretrained_checkpoint_path)\n",
    "        else:\n",
    "            print(\"Starting training from scratch...\")\n",
    "            self.model = self.load_model()\n",
    "        \n",
    "        # Run training\n",
    "        print(\"Starting training...\")\n",
    "        self.trainer.fit(\n",
    "            model=self.model,\n",
    "            datamodule=self.data_module,\n",
    "            ckpt_path=ckpt_path,\n",
    "        )\n",
    "        \n",
    "        print(\"Training complete!\")\n",
    "        return self.trainer.checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "piper_trainer = PiperTrainer(config)\n",
    "\n",
    "# Option 1: Start fresh fine-tuning from pretrained checkpoint\n",
    "# best_checkpoint = piper_trainer.train()\n",
    "\n",
    "# Option 2: Resume from a specific checkpoint\n",
    "# resume_ckpt = config.checkpoint_dir / \"epoch=50-step=10000-val_loss=0.1234.ckpt\"\n",
    "# best_checkpoint = piper_trainer.train(resume_from=resume_ckpt)\n",
    "\n",
    "# Option 3: Auto-resume from latest checkpoint\n",
    "# latest_ckpt = checkpoint_manager.get_latest_checkpoint()\n",
    "# best_checkpoint = piper_trainer.train(resume_from=latest_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resume Training from Checkpoint\n",
    "\n",
    "Utility to easily resume training from an existing checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_training(config: Config, checkpoint_path: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    Resume training from a checkpoint.\n",
    "    \n",
    "    Args:\n",
    "        config: Training configuration\n",
    "        checkpoint_path: Explicit path to checkpoint, or None to auto-detect latest\n",
    "    \"\"\"\n",
    "    checkpoint_manager = CheckpointManager(config)\n",
    "    \n",
    "    if checkpoint_path:\n",
    "        resume_ckpt = Path(checkpoint_path)\n",
    "    else:\n",
    "        # Find latest checkpoint\n",
    "        resume_ckpt = checkpoint_manager.get_latest_checkpoint()\n",
    "    \n",
    "    if resume_ckpt is None:\n",
    "        print(\"No checkpoint found. Starting fresh training.\")\n",
    "        resume_ckpt = config.pretrained_checkpoint_path\n",
    "    else:\n",
    "        print(f\"Resuming from: {resume_ckpt}\")\n",
    "    \n",
    "    # Create trainer and resume\n",
    "    trainer = PiperTrainer(config)\n",
    "    best_checkpoint = trainer.train(resume_from=resume_ckpt)\n",
    "    \n",
    "    return best_checkpoint\n",
    "\n",
    "# Example usage:\n",
    "# best_ckpt = resume_training(config)\n",
    "# Or with explicit checkpoint:\n",
    "# best_ckpt = resume_training(config, \"/path/to/checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ONNX Export for Web Deployment\n",
    "\n",
    "Export the trained model to ONNX format for lightweight web deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Optional\n",
    "\n",
    "class ONNXExporter:\n",
    "    \"\"\"Exports Piper models to ONNX format.\"\"\"\n",
    "    \n",
    "    OPSET_VERSION = 15\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "    \n",
    "    def export(self, checkpoint_path: Path, output_path: Optional[Path] = None) -> Path:\n",
    "        \"\"\"\n",
    "        Export model checkpoint to ONNX format.\n",
    "        \n",
    "        Args:\n",
    "            checkpoint_path: Path to the trained .ckpt file\n",
    "            output_path: Optional output path for .onnx file\n",
    "        \n",
    "        Returns:\n",
    "            Path to the exported ONNX model\n",
    "        \"\"\"\n",
    "        if output_path is None:\n",
    "            output_path = self.config.output_dir / f\"{self.config.voice_name}.onnx\"\n",
    "        \n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        print(f\"Loading checkpoint: {checkpoint_path}\")\n",
    "        model = VitsModel.load_from_checkpoint(checkpoint_path, map_location=\"cpu\")\n",
    "        model_g = model.model_g\n",
    "        \n",
    "        # Set to inference mode\n",
    "        model_g.eval()\n",
    "        \n",
    "        # Remove weight normalization for inference\n",
    "        with torch.no_grad():\n",
    "            model_g.dec.remove_weight_norm()\n",
    "        \n",
    "        # Create inference forward function\n",
    "        def infer_forward(text, text_lengths, scales, sid=None):\n",
    "            noise_scale = scales[0]\n",
    "            length_scale = scales[1]\n",
    "            noise_scale_w = scales[2]\n",
    "            audio = model_g.infer(\n",
    "                text,\n",
    "                text_lengths,\n",
    "                noise_scale=noise_scale,\n",
    "                length_scale=length_scale,\n",
    "                noise_scale_w=noise_scale_w,\n",
    "                sid=sid,\n",
    "            )[0].unsqueeze(1)\n",
    "            return audio\n",
    "        \n",
    "        model_g.forward = infer_forward\n",
    "        \n",
    "        # Prepare dummy inputs\n",
    "        num_symbols = model_g.n_vocab\n",
    "        num_speakers = model_g.n_speakers\n",
    "        \n",
    "        dummy_input_length = 50\n",
    "        sequences = torch.randint(\n",
    "            low=0, high=num_symbols, size=(1, dummy_input_length), dtype=torch.long\n",
    "        )\n",
    "        sequence_lengths = torch.LongTensor([sequences.size(1)])\n",
    "        \n",
    "        sid = None\n",
    "        if num_speakers > 1:\n",
    "            sid = torch.LongTensor([0])\n",
    "        \n",
    "        scales = torch.FloatTensor([0.667, 1.0, 0.8])  # noise, length, noise_w\n",
    "        dummy_input = (sequences, sequence_lengths, scales, sid)\n",
    "        \n",
    "        # Export to ONNX\n",
    "        print(f\"Exporting to ONNX: {output_path}\")\n",
    "        torch.onnx.export(\n",
    "            model=model_g,\n",
    "            args=dummy_input,\n",
    "            f=str(output_path),\n",
    "            verbose=False,\n",
    "            opset_version=self.OPSET_VERSION,\n",
    "            input_names=[\"input\", \"input_lengths\", \"scales\", \"sid\"],\n",
    "            output_names=[\"output\"],\n",
    "            dynamic_axes={\n",
    "                \"input\": {0: \"batch_size\", 1: \"phonemes\"},\n",
    "                \"input_lengths\": {0: \"batch_size\"},\n",
    "                \"output\": {0: \"batch_size\", 2: \"time\"},\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        print(f\"Successfully exported model to: {output_path}\")\n",
    "        \n",
    "        # Also copy the config file\n",
    "        config_output = output_path.with_suffix(\".onnx.json\")\n",
    "        if self.config.config_path.exists():\n",
    "            import shutil\n",
    "            shutil.copy(self.config.config_path, config_output)\n",
    "            print(f\"Copied config to: {config_output}\")\n",
    "        \n",
    "        return output_path\n",
    "    \n",
    "    def verify_onnx(self, onnx_path: Path) -> bool:\n",
    "        \"\"\"Verify the exported ONNX model.\"\"\"\n",
    "        try:\n",
    "            import onnx\n",
    "            import onnxruntime as ort\n",
    "            \n",
    "            # Load and check model\n",
    "            model = onnx.load(str(onnx_path))\n",
    "            onnx.checker.check_model(model)\n",
    "            \n",
    "            # Test inference\n",
    "            session = ort.InferenceSession(str(onnx_path))\n",
    "            print(f\"ONNX model verified successfully!\")\n",
    "            print(f\"Input names: {[i.name for i in session.get_inputs()]}\")\n",
    "            print(f\"Output names: {[o.name for o in session.get_outputs()]}\")\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"ONNX verification failed: {e}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the best checkpoint to ONNX\n",
    "# exporter = ONNXExporter(config)\n",
    "\n",
    "# Use the best checkpoint from training\n",
    "# best_ckpt = Path(best_checkpoint)  # From training step\n",
    "# Or specify a checkpoint path\n",
    "# best_ckpt = config.checkpoint_dir / \"epoch=100-step=20000-val_loss=0.0500.ckpt\"\n",
    "\n",
    "# onnx_path = exporter.export(best_ckpt)\n",
    "# exporter.verify_onnx(onnx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Upload Results to S3 (Optional)\n",
    "\n",
    "Upload the trained model and checkpoints to S3 for backup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_results_to_s3(config: Config, s3_loader: S3DatasetLoader):\n",
    "    \"\"\"Upload trained model and checkpoints to S3.\"\"\"\n",
    "    \n",
    "    # Upload ONNX model\n",
    "    onnx_path = config.output_dir / f\"{config.voice_name}.onnx\"\n",
    "    if onnx_path.exists():\n",
    "        s3_key = f\"{config.s3_checkpoint_prefix}models/{onnx_path.name}\"\n",
    "        s3_loader.upload_checkpoint(onnx_path, s3_key)\n",
    "        print(f\"Uploaded ONNX model to s3://{config.s3_bucket}/{s3_key}\")\n",
    "    \n",
    "    # Upload config\n",
    "    config_path = config.output_dir / f\"{config.voice_name}.onnx.json\"\n",
    "    if config_path.exists():\n",
    "        s3_key = f\"{config.s3_checkpoint_prefix}models/{config_path.name}\"\n",
    "        s3_loader.upload_checkpoint(config_path, s3_key)\n",
    "        print(f\"Uploaded config to s3://{config.s3_bucket}/{s3_key}\")\n",
    "    \n",
    "    # Upload latest checkpoint\n",
    "    checkpoint_manager = CheckpointManager(config)\n",
    "    latest_ckpt = checkpoint_manager.get_latest_checkpoint()\n",
    "    if latest_ckpt:\n",
    "        s3_key = f\"{config.s3_checkpoint_prefix}checkpoints/{latest_ckpt.name}\"\n",
    "        s3_loader.upload_checkpoint(latest_ckpt, s3_key)\n",
    "        print(f\"Uploaded checkpoint to s3://{config.s3_bucket}/{s3_key}\")\n",
    "\n",
    "# Example usage:\n",
    "# upload_results_to_s3(config, s3_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test Inference\n",
    "\n",
    "Test the exported ONNX model with sample text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "\n",
    "def test_onnx_inference(onnx_path: Path, text: str, config: Config):\n",
    "    \"\"\"Test inference with the exported ONNX model.\"\"\"\n",
    "    import onnxruntime as ort\n",
    "    import json\n",
    "    \n",
    "    # Add piper to path for phonemization\n",
    "    sys.path.insert(0, '/tmp/piper1-gpl/src')\n",
    "    from piper.phonemize_espeak import EspeakPhonemizer\n",
    "    from piper.phoneme_ids import phonemes_to_ids\n",
    "    \n",
    "    # Load config\n",
    "    config_path = onnx_path.with_suffix(\".onnx.json\")\n",
    "    with open(config_path, 'r') as f:\n",
    "        model_config = json.load(f)\n",
    "    \n",
    "    # Phonemize text\n",
    "    phonemizer = EspeakPhonemizer()\n",
    "    phonemes = phonemizer.phonemize(config.espeak_voice, text)\n",
    "    \n",
    "    # Convert to IDs\n",
    "    phoneme_ids = []\n",
    "    for sentence_phonemes in phonemes:\n",
    "        phoneme_ids.extend(phonemes_to_ids(sentence_phonemes))\n",
    "    \n",
    "    # Prepare inputs\n",
    "    input_ids = np.array([phoneme_ids], dtype=np.int64)\n",
    "    input_lengths = np.array([len(phoneme_ids)], dtype=np.int64)\n",
    "    scales = np.array([0.667, 1.0, 0.8], dtype=np.float32)  # noise, length, noise_w\n",
    "    \n",
    "    # Run inference\n",
    "    session = ort.InferenceSession(str(onnx_path))\n",
    "    \n",
    "    inputs = {\n",
    "        \"input\": input_ids,\n",
    "        \"input_lengths\": input_lengths,\n",
    "        \"scales\": scales,\n",
    "    }\n",
    "    \n",
    "    # Add speaker ID if multi-speaker\n",
    "    if model_config.get(\"num_speakers\", 1) > 1:\n",
    "        inputs[\"sid\"] = np.array([0], dtype=np.int64)\n",
    "    \n",
    "    output = session.run(None, inputs)[0]\n",
    "    \n",
    "    # Convert to audio\n",
    "    audio = output.squeeze()\n",
    "    \n",
    "    return audio, config.sample_rate\n",
    "\n",
    "# Example usage:\n",
    "# onnx_path = config.output_dir / f\"{config.voice_name}.onnx\"\n",
    "# audio, sr = test_onnx_inference(onnx_path, \"Hello, this is a test of Indian English voice.\", config)\n",
    "# Audio(audio, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides a complete pipeline for:\n",
    "\n",
    "1. **Environment Setup**: Compatible with both Google Colab and AWS SageMaker\n",
    "2. **Configuration**: Modular configuration with placeholders for S3 bucket, paths, etc.\n",
    "3. **Dataset ETL**: Download SPICOR dataset from S3\n",
    "4. **Data Preprocessing**: Convert to Piper-compatible format\n",
    "5. **Checkpoint Management**: Download pretrained checkpoint from HuggingFace\n",
    "6. **Fine-Tuning**: Train with frequent checkpointing (every N steps/epochs)\n",
    "7. **Resume Training**: Easily resume from any checkpoint\n",
    "8. **ONNX Export**: Export to lightweight format for web deployment\n",
    "9. **S3 Backup**: Upload results to S3 for persistence\n",
    "10. **Inference Testing**: Verify the exported model\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Update the configuration placeholders with your actual S3 bucket and paths\n",
    "2. Upload your SPICOR dataset to S3\n",
    "3. Run the cells in order to train and export your model\n",
    "4. Use the exported `.onnx` and `.onnx.json` files for web deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
